{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5deea49f",
   "metadata": {},
   "source": [
    "This code processes EDA and event-related data from .csv files generated by BIOPAC or similar devices. It structures and analyzes this data by applying conditions to identify events, downsampling the data, and organizing it for further analysis.  \n",
    "\n",
    "Digital Channels: BIOPAC uses a set of digital input channels (e.g., 8 channels, D0 to D7).\n",
    "Bit Position: \n",
    "D0 = 2^0 = 1  \n",
    "D1 = 2^1 = 2 \n",
    "D2 = 2^2 = 4 \n",
    "D3 = 2^3 = 8 \n",
    "D4 = 2^4 = 16 \n",
    "D5 = 2^5 = 32 \n",
    "D6 = 2^6 = 64 \n",
    "D7 = 2^7 = 128 \n",
    "\n",
    "Stim is in channel 16 (stim channel) \n",
    "GSR - EDA100C\t\n",
    "CORR - EMG100C\t\n",
    "ECG - ECG100C\t\n",
    "Feedback Cable - CBLCFMA - Current Feed\t\n",
    "Stim - Custom, AMI / HLT - A16\t\n",
    "Digital (STP Input 0)\t\n",
    "Digital (STP Input 1)\t\n",
    "Digital (STP Input 2)\t\n",
    "Digital (STP Input 3)\t\n",
    "Digital (STP Input 4)\t\n",
    "Digital (STP Input 5)\t\n",
    "Digital (STP Input 6)\t\n",
    "Digital (STP Input 7) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8bbb0",
   "metadata": {},
   "source": [
    "Event Code Notes (which digital channels): \n",
    "Flanker Stimulus appears: 128 (channel: 7)\n",
    "\n",
    "Each countdown/run starts with either: \n",
    "An event_code_countdown_start or event_code_flanker_start \n",
    "After the start of the flanker trial - there are these event codes: event_code_flanker \n",
    " \n",
    "countdown_end - this is when the whole coundfown section (60 seconds) ends and the electric shock is about to start. \n",
    "\n",
    "Note: errors from prev. script. keep just in case. \n",
    "In distal_shock condition: \n",
    "--- mistake countdown end: 91 (channel: 0, 1, 3, 6)\n",
    "prox stim \n",
    "------ mistake - - countdown end: 92 (channels: 2, 3, 6 )\n",
    "/end \n",
    "\n",
    "\n",
    "\n",
    "In distal_shock condition: \n",
    "countdown start: 81 (channel: 0, 4, 6 )\n",
    "countdown end: 91 (channel: 0, 1, 3, 4, 6) *** fixed \n",
    "flanker start: 4 (channel: 2)\n",
    "flanker end: 5 (channels: 0, 2)\n",
    "\n",
    "In proximal_shock condition:\n",
    "countdown start: 82 (channel: 1, 4, 6 )\n",
    "countdown end: 92 (channels: 2, 3, 4, 6 ) *** fixed \n",
    "flanker start: 8 (channel: 3)\n",
    "flanker end: 9(channels: 0, 3)\n",
    "\n",
    "In distal_light_stim condition:\n",
    "countdown start: 84 (channels: 2, 4, 6)\n",
    "countdown end: 94 (channels: 0, 1, 2, 3, 4, 6 )\n",
    "flanker start: 32 (channel: 5) \n",
    "flanker end: 33 (channels: 0, 5) \n",
    "\t\t \t\n",
    "In proximal_light_stim condition: \n",
    "countdown start: 85\t(channels: 0, 2, 4, 6) \n",
    "countdown end: 95 (channels: 0, 1, 2, 3, 4, 6)\n",
    "flanker start: 64 (channel 6) \n",
    "flanker end: 65 (channels: 0, 6) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae0c11",
   "metadata": {},
   "source": [
    "- This code runs through each subject, then through each task file from that subject.\n",
    "- It imports the raw data of the task file (but aleady be in csv format after running an acq_to_mat script). \n",
    "- Each columns is a biopac channel (analog and digital channel).  \n",
    "- Each row represents a time point, with values captured based on the sampling rate (e.g., 2000 Hz = 2000 rows per second).\n",
    "- When an event code appears that event code tiggers a quick blip in the digital channels (either one or a combination of digital channels (cheat sheet above)). \n",
    "- To extract specific parts of the block - find the rows that have specific event codes. \n",
    "- Then break the data into 4 countdowns (there were 4 countdowns per block)  \n",
    "- Label those parts of the block \n",
    "- Downsample (every 20th row) to make it a lower temporal resolution \n",
    "- Repeat with each block \n",
    "- Concatenate all the selected parts of the data into one file \n",
    "- Export as text file \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83867a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    blockNum  intervalNum time_condition  shock_cond\n",
      "0          1            1       proximal       shock\n",
      "1          1            2         distal       shock\n",
      "2          1            3       proximal  light_stim\n",
      "3          1            4         distal  light_stim\n",
      "4          2            5       proximal  light_stim\n",
      "5          2            6       proximal       shock\n",
      "6          2            7         distal  light_stim\n",
      "7          2            8         distal       shock\n",
      "8          3            9       proximal       shock\n",
      "9          3           10         distal       shock\n",
      "10         3           11         distal  light_stim\n",
      "11         3           12       proximal  light_stim\n",
      "12         4           13       proximal  light_stim\n",
      "13         4           14         distal  light_stim\n",
      "14         4           15       proximal       shock\n",
      "15         4           16         distal       shock\n",
      "16         5           17       proximal  light_stim\n",
      "17         5           18         distal       shock\n",
      "18         5           19         distal  light_stim\n",
      "19         5           20       proximal       shock\n",
      "20         6           21         distal       shock\n",
      "21         6           22       proximal  light_stim\n",
      "22         6           23         distal  light_stim\n",
      "23         6           24       proximal       shock\n",
      "24         7           25       proximal       shock\n",
      "25         7           26         distal  light_stim\n",
      "26         7           27         distal       shock\n",
      "27         7           28       proximal  light_stim\n",
      "28         8           29       proximal  light_stim\n",
      "29         8           30         distal       shock\n",
      "30         8           31         distal  light_stim\n",
      "31         8           32       proximal       shock\n",
      "32         9           33         distal       shock\n",
      "33         9           34         distal  light_stim\n",
      "34         9           35       proximal       shock\n",
      "35         9           36       proximal  light_stim\n"
     ]
    }
   ],
   "source": [
    "# List of conditions for sub 3 (36 countdowns) - info to double check if this script matches up \n",
    "# import csv \n",
    "\n",
    "import pandas as pd\n",
    "file_path = \"/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/pipeline_psychopyz_nadu/sub_3_conditions.csv\"\n",
    "df = pd.read_csv(file_path, index_col=None)\n",
    "df.reset_index(drop=True, inplace=True)  # Reset the index and remove the old one\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "# 6 and 0 - end code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586ed8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb278d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d63a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first column is time \n",
    "# second col is EDA \n",
    "# third column is event \n",
    "\n",
    "\n",
    "# get a start code \n",
    "# then start +60 seconds \n",
    "# export as csv \n",
    "# new index \n",
    "# next start code + 60 seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e9eeb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1633472226.py, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 63\u001b[0;36m\u001b[0m\n\u001b[0;31m    ]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Script for collapsing across digital channels\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#the timing files we want to get are three columns  - timestamp,  event code, event name\n",
    "#import csv that you created, select the EDA column (& HR)\n",
    "\n",
    "# change these \n",
    "save_dir = \"/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/acq_data/EDA_processed\"\n",
    "rawdata = \"/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/acq_data/fmcc_csv\"\n",
    "IDs = [\"03\"]\n",
    " \n",
    "\n",
    "#We need to record the start event code conditions for runs so that it can be used for the other analysis\n",
    "subject = []\n",
    "runli = []\n",
    "startcode = []\n",
    "runs = [8]\n",
    " \n",
    "\n",
    "#Define a function that find the index of not none elements in the list\n",
    "def find_non_none_indices(lst):\n",
    "    indices = [i for i, element in enumerate(lst) if element != 'none']\n",
    "    return indices\n",
    "\n",
    "for ID in IDs:\n",
    "    for run in runs:\n",
    "        print(run)\n",
    "        subject.append(ID)\n",
    "        runli.append(run) # in the end you have info to make a spreadsheet \n",
    "        current_dir = rawdata + \"/\" + ID\n",
    "        current_file = \"fmcc_sub\" + ID + \"_task_000\" + str(run) + \".csv\"\n",
    "        path = os.path.join(current_dir, current_file)\n",
    "\n",
    "        tmp_df = pd.read_csv(path, header=None, delimiter=',') #your txt or csv file from acqknowledge\n",
    "        #print(tmp_df.head())\n",
    "        # Current columns = EDA, CORR, ECG, Feedback, Stim, ch1-8\n",
    "        #Let's remove the COrr & Feedback columns\n",
    "\n",
    "        data = (tmp_df #make a copy of the df and...\n",
    "        .drop(index=0)  # remove the first row\n",
    "        .drop(columns=[1, 3])  # drop columns 1 and 3 (Corr & Feedback)\n",
    "        .reset_index(drop=True))  # reset row index\n",
    "        data.head()\n",
    "        \n",
    "        print(data) #take a look at the original data\n",
    "\n",
    "        #rename the channels to make sense\n",
    "        data.columns = ['EDA', 'ECG', 'Stim', 'ch0', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7']# renaming the channels from 0 - 7 instead of 1 - 8 based on Nadu's event code convention\n",
    "\t\n",
    "        #Get the start of the countdown - this will be the codes for countdown_start OR flanker_start:\n",
    "        conditions = [\n",
    "             ((data['ch0'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5)& (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #distal shock countdown start\n",
    "            ((data['ch1'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & (data['ch0'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #proximal shock countdown start\n",
    "            ((data['ch2'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & (data['ch1'] == 0) & (data['ch0'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #distal stim countdown start\n",
    "            ((data['ch0'] == 5) & (data['ch2'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & (data['ch1'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #proximal stim countdown start\n",
    "\n",
    "#              ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 5)& (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & (data['ch6'] == 0 ) & (data['ch7'] == 0 )) | #distal shock flanker start\n",
    "#              ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & (data['ch6'] == 0 ) & (data['ch7'] == 0 )) | #proximal shock flanker start\n",
    "#              ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 5) & (data['ch6'] == 0) & (data['ch7'] == 0 )) | #distal stim flanker start\n",
    "#              ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & (data['ch6'] == 5 ) & (data['ch7'] == 0 ))  #proximal stim flanker start\n",
    "      ]\n",
    "        \n",
    "        values = ['start', 'start', 'start', 'start']\n",
    "        \n",
    "        data['start'] = np.select(conditions, values, default=\"none\")\n",
    "\n",
    "       \n",
    "        # deleted start line of code \n",
    "\n",
    "    #Notes from Jingyi's code that I don't think we need\n",
    "        #divide the dataframe into four sections, two encoding sections, two task sections\n",
    "        # Find the index of the first occurrence of the value\n",
    "        #ps: +20 to make sure all the event code for 211 is removed.\n",
    "        #index = data['start'].tolist().index('start') + 40\n",
    "\n",
    "        #index = data['start'].tolist().index('start') #this line finds the index of the first occurrence of 'start' in the 'start' column -  9033698\n",
    "\n",
    "        #first get the start_li and downsample - this is downsampling the 'start' column only for now by getting every 20th value \n",
    "        Start_li = data['start'].tolist()[::20] # creates a new list of the 'start' column\n",
    "        \n",
    "        Start_num = find_non_none_indices(Start_li) # this finds the index of every 'start' occurrence \n",
    "        startcode.append(len(Start_num)) \n",
    "\n",
    "        #then, Jingyi has if/then statements where she looks at the length of that Start_num list to see how many occurrences there were and she differentially works on the data - I don't think we need to do this\n",
    "\n",
    "        #Instead, we are going to get a list of all of the first-instances of start (non-consecutive) to get the start of every countdown\n",
    "        #start_indices = []\n",
    "        #prev_value = None\n",
    "        \n",
    "        # for index, value in enumerate(data[\"column_name\"])\n",
    "        \n",
    "        # Iterate over the 'start' column and check for transitions\n",
    "        #for i, value in enumerate(data['start']):\n",
    "           # if value == 'start' and (prev_value != 'start'):  # First occurrence of 'start'\n",
    "            #    start_indices.append(i)\n",
    "           # prev_value = value\n",
    "       # print(start_indices) # [0, 903698, 905675, 907669, 909689, 911659, 913688, 915685, 917661, 919679, 921671, 923673, 925694, 927669, 929669, 931663, 933667, 935662, 937669, 939679, 941671, 943660, 945674, 947686, 949692, 951683, 953685, 955675, 957680, 959672, 961679, 963669, 965666]\n",
    "       # len(start_indices) # [33]\n",
    "\n",
    "        \n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2919b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we can slice the df into the different task epochs - countdown & flanker - we can do this for the different conditions\n",
    "\n",
    "        # let's first create new columns that define the condition & timing:\n",
    "        condition_conditions = [\n",
    "            # Distal shock conditions\n",
    "            ((data['ch0'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & \n",
    "            (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & \n",
    "            (data['ch5'] == 0) & (data['ch7'] == 0)), # distal shock countdown start \n",
    "\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 5) & (data['ch3'] == 5) & \n",
    "             (data['ch4'] == 5) & (data['ch6'] == 5) & (data['ch2'] == 0) & \n",
    "             (data['ch5'] == 0) & (data['ch7'] == 0)),  # distal shock countdown end *** fixed: channel 0, 1, 3, 4, 6\n",
    "\n",
    "            ((data['ch2'] == 5) & (data['ch0'] == 0) & (data['ch1'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal shock flanker start \n",
    "\n",
    "            ((data['ch2'] == 5) & (data['ch0'] == 5) & (data['ch1'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal shock flanker end \n",
    "\n",
    "            # Proximal shock conditions\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 5) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal shock countdown start \n",
    "\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal shock countdown end \n",
    "\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # proximal shock flanker start \n",
    "\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # proximal shock flanker end \n",
    "\n",
    "            # Distal stim conditions\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # distal stim countdown start \n",
    "\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 5) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # distal stim countdown end \n",
    "\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 5) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal stim flanker start \n",
    "\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 5) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal stim flanker end \n",
    "\n",
    "            # Proximal stim conditions\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal stim countdown start\n",
    "\n",
    "             ((data['ch2'] == 5) & (data['ch3'] == 5) & (data['ch4'] == 5) & \n",
    "             (data['ch6'] == 5) & (data['ch0'] == 0) & (data['ch1'] == 0) & \n",
    "             (data['ch5'] == 0) & (data['ch7'] == 0)),  # proximal stim countdown end *** fixed: channel 2, 3, 4, 6\n",
    "\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal stim flanker start\n",
    "\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)) # proximal stim flanker end \n",
    "        ]\n",
    "\n",
    "\n",
    "        # Define corresponding condition values\n",
    "        condition_values = [\n",
    "            'distal shock', 'distal shock', 'distal shock', 'distal shock',\n",
    "            'proximal shock', 'proximal shock', 'proximal shock', 'proximal shock',\n",
    "            'distal stim', 'distal stim', 'distal stim', 'distal stim',\n",
    "            'proximal stim', 'proximal stim', 'proximal stim', 'proximal stim'\n",
    "        ]\n",
    "        data['condition'] = np.select(condition_conditions, condition_values, default='none')\n",
    "        \n",
    "        epoch_values = [\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end',\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end',\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end',\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end'\n",
    "        ]\n",
    "\n",
    "\n",
    "        data['epoch'] = np.select(condition_conditions, epoch_values, default='none')\n",
    "        event_values = [1, 2, 3, 4, 5, 6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "        # 1 = distal shock countdown start\n",
    "        # 2 = distal shock countdown end - we dont have this\n",
    "        # 3 = distal shock flanker start\n",
    "        # 4 = distal shock flanker end\n",
    "        # 5 = proximal shock countdown start\n",
    "        # 6 = proximal shock countdown end - we dont have this \n",
    "        # 7 = proximal shock flanker start\n",
    "        # 8 = proximal shock flanker end\n",
    "        # 9 = distal stim countdown start\n",
    "        # 10 = distal stim countdown end\n",
    "        # 11 = distal stim flanker start\n",
    "        # 12 = distal stim flanker end\n",
    "        # 13 = proximal stim countdown start\n",
    "        # 14 = proximal stim countdown end\n",
    "        # 15 = proximal stim flanker start\n",
    "        # 16 = proximal stim flanker end \n",
    "\n",
    "        #then add a new column to our data frame based on these conditions\n",
    "        data['Event'] = np.select(condition_conditions, event_values)\n",
    "        \n",
    "        #remove columns to clean up the df\n",
    "        columns_to_remove = ['ch0', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7']\n",
    "        data_sub = data.drop(columns=columns_to_remove)\n",
    "        \n",
    "        #print(data_sub) \n",
    "\n",
    "        # Construct the file name for the downsampled data\n",
    "        test_file = os.path.join(save_dir, f\"test_label_{ID}_run{run + 1}.csv\")\n",
    "\n",
    "        # Save the downsampled data as a CSV file\n",
    "        data_sub.to_csv(test_file, index=False)\n",
    "        print(\"saved as csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29567b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_downsampled = data_sub[::20].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "        # lets also get a list of indices of the first instance of an event (non-consecutive)\n",
    "        event_indices = data_sub[data_sub['Event'] != data_sub['Event'].shift(1)].index.tolist()\n",
    "        event_indices = [i for i in event_indices if data_sub.loc[i, 'Event'] != 0]\n",
    "        print(event_indices)\n",
    "        \n",
    "        # [4713, 6678, 8683, 10695, 12710, 14691, 16698, 18684, 20719, 22689, 24701, 26681, 28697, 30685, 32686, 34717, 36702, 38696, 40705, 42685, 44689, 46706, 48690, 50697, 52700, 54687, 56689, 58693, 60686, 62684, 64689, 66700, 124665, 151289, 153269, 153332, 213351, 213402, 215424, 217429, 219403, 221422, 223416, 225412, 227401, 229417, 231421, 233425, 235424, 237423, 239416, 241449, 243419, 245413, 247411, 249416, 251426, 253417, 255406, 257407, 259409, 261411, 263421, 265409, 267424, 269403, 271287, 271364, 297844, 299831, 359818, 359880, 361896, 363890, 365886, 367869, 369872, 371896, 373892, 375904, 377876, 379871, 381876, 383891, 385884, 387873, 389884, 391871, 393893, 395885, 397877, 399879, 401881, 403878, 405892, 407899, 409880, 411899, 413869, 415893, 417875, 417948, 418173, 441798, 443801, 445815, 447807, 449836, 451794, 453804, 455807, 457805, 459795, 461797, 463801, 465806, 467790, 469790, 471809, 473808, 475804, 477797, 479805, 481812, 483816, 485809, 487805, 489795, 491812, 493788, 495817, 497805, 499788, 501789, 503824, 561773, 562005]\n",
    "        # these include 'countdown start' for every number in the countdown\n",
    "\n",
    "        # preview a slice of the df\n",
    "        print(data_sub.iloc[4710:4750])\n",
    "\n",
    "\n",
    "        # let's slice the events from the beginning of one 'start' to the beginning of the next 'start' \n",
    "        # so start indices = [4713, 6678, 8683, 10695, 12710, 14691, 16698, 18684, 20719, 22689, 24701, 26681, 28697, 30685, 32686, 34717, 36702, 38696, 40705, 42685, 44689, 46706, 48690, 50697, 52700, 54687, 56689, 58693, 60686, 62684, 64689, 66700, 151289, 153269, 153332, 213402, 215424, 217429, 219403, 221422, 223416, 225412, 227401, 229417, 231421, 233425, 235424, 237423, 239416, 241449, 243419, 245413, 247411, 249416, 251426, 253417, 255406, 257407, 259409, 261411, 263421, 265409, 267424, 269403, 271287, 297844, 299831, 359880, 361896, 363890, 365886, 367869, 369872, 371896, 373892, 375904, 377876, 379871, 381876, 383891, 385884, 387873, 389884, 391871, 393893, 395885, 397877, 399879, 401881, 403878, 405892, 407899, 409880, 411899, 413869, 415893, 417875, 441798, 443801, 445815, 447807, 449836, 451794, 453804, 455807, 457805, 459795, 461797, 463801, 465806, 467790, 469790, 471809, 473808, 475804, 477797, 479805, 481812, 483816, 485809, 487805, 489795, 491812, 493788, 495817, 497805, 499788, 501789, 503824]\n",
    "\n",
    "        # then our slices will be : [0:903697, 903698 : 905674, 905675 : 907668,etc]\n",
    "\n",
    "        # the unique events we have are 5  7  8  1  3  4  9 11 12 10 13 15 16 14\n",
    "\n",
    "        slices = [(start_indices[i], start_indices[i + 1] - 1) for i in range(len(start_indices) - 1)]\n",
    "        # Include the final slice\n",
    "        slices.append((start_indices[-1], 'end')) \n",
    "        print(slices)\n",
    "\n",
    "        #now we're going to loop through that list of the countdown start indices and block out where the events start\n",
    "        #for x in start_indices:\n",
    "           #print(x)\n",
    "           # data_tmp = data_sub.iloc[x:]\n",
    "            \n",
    "        #reset index\n",
    "        # data_tmp.reset_index(inplace=True, drop=True)\n",
    "        #data_tmp.head()\n",
    "        \n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46ea60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94fd39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cb121c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "         0         1         2         3         4    5    6    7    8     9   \\\n",
      "0  1.000000  2.000000  3.000000  4.000000  5.000000  6.0  7.0  8.0  9.0  10.0   \n",
      "1  2.540402 -0.012207  0.643921  0.314331 -0.209346  0.0  0.0  0.0  0.0   0.0   \n",
      "2  2.537350 -0.009155  0.650330  0.299072 -0.207210  0.0  0.0  0.0  0.0   0.0   \n",
      "3  2.541928  0.022888  0.656738  0.332642 -0.206600  0.0  0.0  0.0  0.0   0.0   \n",
      "4  2.540402  0.051880  0.662537  0.308228 -0.209652  0.0  0.0  0.0  0.0   0.0   \n",
      "\n",
      "     10    11    12  \n",
      "0  11.0  12.0  13.0  \n",
      "1   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'start' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 52\u001b[0m\n\u001b[1;32m     42\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mselect(conditions, values, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#Notes from Jingyi's code that I don't think we need\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#divide the dataframe into four sections, two encoding sections, two task sections\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Find the index of the first occurrence of the value\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m#ps: +20 to make sure all the event code for 211 is removed.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m#index = data['start'].tolist().index('start') + 40\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     index \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#this line finds the index of the first occurrence of 'start' in the 'start' column -  9033698\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#first get the start_li and downsample - this is downsampling the 'start' column only for now by getting every 20th value \u001b[39;00m\n\u001b[1;32m     55\u001b[0m     Start_li \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[::\u001b[38;5;241m20\u001b[39m] \u001b[38;5;66;03m# creates a new list of the 'start' column\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'start' is not in list"
     ]
    }
   ],
   "source": [
    "runs = [2]\n",
    "def find_non_none_indices(lst):\n",
    "    indices = [i for i, element in enumerate(lst) if element != 'none']\n",
    "    return indices\n",
    "\n",
    "for ID in IDs:\n",
    "    for run in runs:\n",
    "        print(run)\n",
    "        subject.append(ID)\n",
    "        runli.append(run)\n",
    "        current_dir = rawdata + \"/\" + ID\n",
    "        current_file = \"fmcc_sub\" + ID + \"_task_000\" + str(run) + \".csv\"\n",
    "        path = os.path.join(current_dir, current_file)\n",
    "\n",
    "        tmp_df = pd.read_csv(path, header=None, delimiter=',') #your txt or csv file from acqknowledge\n",
    "        print(tmp_df.head())\n",
    "        # Current columns = EDA, CORR, ECG, Feedback, Stim, ch1-8\n",
    "        #Let's remove the COrr & Feedback columns\n",
    "\n",
    "        data = (tmp_df #make a copy of the df and...\n",
    "        .drop(index=0)  # remove the first row\n",
    "        .drop(columns=[1, 3])  # drop columns 1 and 3 (Corr & Feedback)\n",
    "        .reset_index(drop=True))  # reset row index\n",
    "        data.head()\n",
    "        #rename the channels to make sense\n",
    "        data.columns = ['EDA', 'ECG', 'Stim', 'ch0', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7']# renaming the channels from 0 - 7 instead of 1 - 8 based on Nadu's event code convention\n",
    "\t\n",
    "        #Get the start of the countdown - this will be the codes for countdown_start OR flanker_start:\n",
    "        conditions = [\n",
    "            ((data['ch0'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5)& (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #distal shock countdown start\n",
    "            ((data['ch1'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & (data['ch0'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #proximal shock countdown start\n",
    "            ((data['ch2'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & (data['ch1'] == 0) & (data['ch0'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #distal stim countdown start\n",
    "            ((data['ch0'] == 5) & (data['ch2'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & (data['ch1'] == 0) & (data['ch3'] == 0) & (data['ch5'] == 0 ) & (data['ch7'] == 0 )) | #proximal stim countdown start\n",
    "\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 5)& (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & (data['ch6'] == 0 ) & (data['ch7'] == 0 )) | #distal shock flanker start\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & (data['ch6'] == 0 ) & (data['ch7'] == 0 )) | #proximal shock flanker start\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 5) & (data['ch6'] == 0) & (data['ch7'] == 0 )) | #distal stim flanker start\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & (data['ch6'] == 5 ) & (data['ch7'] == 0 ))  #proximal stim flanker start\n",
    "        ]\n",
    "        values = [\"start\"]\n",
    "        # add a new column to put the start point\n",
    "        data['start'] = np.select(conditions, values, default=\"none\")\n",
    "\n",
    "\n",
    "    #Notes from Jingyi's code that I don't think we need\n",
    "        #divide the dataframe into four sections, two encoding sections, two task sections\n",
    "        # Find the index of the first occurrence of the value\n",
    "        #ps: +20 to make sure all the event code for 211 is removed.\n",
    "        #index = data['start'].tolist().index('start') + 40\n",
    "\n",
    "\n",
    "        index = data['start'].tolist().index('start') #this line finds the index of the first occurrence of 'start' in the 'start' column -  9033698\n",
    "\n",
    "        #first get the start_li and downsample - this is downsampling the 'start' column only for now by getting every 20th value \n",
    "        Start_li = data['start'].tolist()[::20] # creates a new list of the 'start' column\n",
    "        Start_num = find_non_none_indices (Start_li) # this finds the index of every 'start' occurrence \n",
    "        startcode.append(len(Start_num)) \n",
    "\n",
    "        #then, Jingyi has if/then statements where she looks at the length of that Start_num list to see how many occurrences there were and she differentially works on the data - I don't think we need to do this\n",
    "\n",
    "        #Instead, we are going to get a list of all of the first-instances of start (non-consecutive) to get the start of every countdown\n",
    "        start_indices = []\n",
    "        prev_value = None\n",
    "        # Iterate over the 'start' column and check for transitions\n",
    "        for i, value in enumerate(data['start']):\n",
    "            if value == 'start' and (prev_value != 'start'):  # First occurrence of 'start'\n",
    "                start_indices.append(i)\n",
    "            prev_value = value\n",
    "        print(start_indices) # [0, 903698, 905675, 907669, 909689, 911659, 913688, 915685, 917661, 919679, 921671, 923673, 925694, 927669, 929669, 931663, 933667, 935662, 937669, 939679, 941671, 943660, 945674, 947686, 949692, 951683, 953685, 955675, 957680, 959672, 961679, 963669, 965666]\n",
    "        len(start_indices) # [33]\n",
    "\n",
    "        # next, we can slice the df into the different task epochs - countdown & flanker - we can do this for the different conditions\n",
    "\n",
    "        # let's first create new columns that define the condition & timing:\n",
    "        condition_conditions = [\n",
    "            # Distal shock conditions\n",
    "            ((data['ch0'] == 5) & (data['ch4'] == 5) & (data['ch6'] == 5) & \n",
    "            (data['ch1'] == 0) & (data['ch2'] == 0) & (data['ch3'] == 0) & \n",
    "            (data['ch5'] == 0) & (data['ch7'] == 0)), # distal shock countdown start \n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 5) & (data['ch3'] == 5) & \n",
    "            (data['ch6'] == 5) & (data['ch2'] == 0) & (data['ch4'] == 0) & \n",
    "            (data['ch5'] == 0) & (data['ch7'] == 0)), # distal shock countdown end \n",
    "            ((data['ch2'] == 5) & (data['ch0'] == 0) & (data['ch1'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal shock flanker start \n",
    "            ((data['ch2'] == 5) & (data['ch0'] == 5) & (data['ch1'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal shock flanker end \n",
    "\n",
    "            # Proximal shock conditions\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 5) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal shock countdown start \n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal shock countdown end \n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # proximal shock flanker start \n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # proximal shock flanker end \n",
    "\n",
    "            # Distal stim conditions\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # distal stim countdown start \n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 5) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # distal stim countdown end \n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 5) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal stim flanker start \n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 5) & \n",
    "            (data['ch6'] == 0) & (data['ch7'] == 0)), # distal stim flanker end \n",
    "\n",
    "            # Proximal stim conditions\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal stim countdown start\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 5) & (data['ch2'] == 5) & \n",
    "            (data['ch3'] == 5) & (data['ch4'] == 5) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal stim countdown end\n",
    "            ((data['ch0'] == 0) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)), # proximal stim flanker start\n",
    "            ((data['ch0'] == 5) & (data['ch1'] == 0) & (data['ch2'] == 0) & \n",
    "            (data['ch3'] == 0) & (data['ch4'] == 0) & (data['ch5'] == 0) & \n",
    "            (data['ch6'] == 5) & (data['ch7'] == 0)) # proximal stim flanker end \n",
    "        ]\n",
    "\n",
    "        # Define corresponding condition values\n",
    "        condition_values = [\n",
    "            'distal shock', 'distal shock', 'distal shock', 'distal shock',\n",
    "            'proximal shock', 'proximal shock', 'proximal shock', 'proximal shock',\n",
    "            'distal stim', 'distal stim', 'distal stim', 'distal stim',\n",
    "            'proximal stim', 'proximal stim', 'proximal stim', 'proximal stim'\n",
    "        ]\n",
    "        data['condition'] = np.select(condition_conditions, condition_values, default='none')\n",
    "        epoch_values = [\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end',\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end',\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end',\n",
    "            'countdown start', 'countdown end', 'flanker start', 'flanker end'\n",
    "        ]\n",
    "        data['epoch'] = np.select(condition_conditions, epoch_values, default='none')\n",
    "        event_values = [1, 2, 3, 4, 5, 6,7,8,9,10,11,12,13,14,15,16]\n",
    "        # 1 = distal shock countdown start\n",
    "        # 2 = distal shock countdown end - we dont have this\n",
    "        # 3 = distal shock flanker start\n",
    "        # 4 = distal shock flanker end\n",
    "        # 5 = proximal shock countdown start\n",
    "        # 6 = proximal shock countdown end - we dont have this \n",
    "        # 7 = proximal shock flanker start\n",
    "        # 8 = proximal shock flanker end\n",
    "        # 9 = distal stim countdown start\n",
    "        # 10 = distal stim countdown end\n",
    "        # 11 = distal stim flanker start\n",
    "        # 12 = distal stim flanker end\n",
    "        # 13 = proximal stim countdown start\n",
    "        # 14 = proximal stim countdown end\n",
    "        # 15 = proximal stim flanker start\n",
    "        # 16 = proximal stim flanker end \n",
    "\n",
    "        #then add a new column to our data frame based on these conditions\n",
    "        data['Event'] = np.select(condition_conditions, event_values)\n",
    "        \n",
    "        #remove columns to clean up the df\n",
    "        columns_to_remove = ['ch0', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7']\n",
    "        data_sub = data.drop(columns=columns_to_remove)\n",
    "\n",
    "        # lets also get a list of indices of the first instance of an event (non-consecutive)\n",
    "        event_indices = data_sub[data_sub['Event'] != data_sub['Event'].shift(1)].index.tolist()\n",
    "        event_indices = [i for i in event_indices if data_sub.loc[i, 'Event'] != 0]\n",
    "        print(event_indices)\n",
    "        # [4713, 6678, 8683, 10695, 12710, 14691, 16698, 18684, 20719, 22689, 24701, 26681, 28697, 30685, 32686, 34717, 36702, 38696, 40705, 42685, 44689, 46706, 48690, 50697, 52700, 54687, 56689, 58693, 60686, 62684, 64689, 66700, 124665, 151289, 153269, 153332, 213351, 213402, 215424, 217429, 219403, 221422, 223416, 225412, 227401, 229417, 231421, 233425, 235424, 237423, 239416, 241449, 243419, 245413, 247411, 249416, 251426, 253417, 255406, 257407, 259409, 261411, 263421, 265409, 267424, 269403, 271287, 271364, 297844, 299831, 359818, 359880, 361896, 363890, 365886, 367869, 369872, 371896, 373892, 375904, 377876, 379871, 381876, 383891, 385884, 387873, 389884, 391871, 393893, 395885, 397877, 399879, 401881, 403878, 405892, 407899, 409880, 411899, 413869, 415893, 417875, 417948, 418173, 441798, 443801, 445815, 447807, 449836, 451794, 453804, 455807, 457805, 459795, 461797, 463801, 465806, 467790, 469790, 471809, 473808, 475804, 477797, 479805, 481812, 483816, 485809, 487805, 489795, 491812, 493788, 495817, 497805, 499788, 501789, 503824, 561773, 562005]\n",
    "        # these include 'countdown start' for every number in the countdown\n",
    "\n",
    "        # preview a slice of the df\n",
    "        print(data_sub.iloc[4710:4750])\n",
    "\n",
    "\n",
    "        # let's slice the events from the beginning of one 'start' to the beginning of the next 'start' \n",
    "        # so start indices = [4713, 6678, 8683, 10695, 12710, 14691, 16698, 18684, 20719, 22689, 24701, 26681, 28697, 30685, 32686, 34717, 36702, 38696, 40705, 42685, 44689, 46706, 48690, 50697, 52700, 54687, 56689, 58693, 60686, 62684, 64689, 66700, 151289, 153269, 153332, 213402, 215424, 217429, 219403, 221422, 223416, 225412, 227401, 229417, 231421, 233425, 235424, 237423, 239416, 241449, 243419, 245413, 247411, 249416, 251426, 253417, 255406, 257407, 259409, 261411, 263421, 265409, 267424, 269403, 271287, 297844, 299831, 359880, 361896, 363890, 365886, 367869, 369872, 371896, 373892, 375904, 377876, 379871, 381876, 383891, 385884, 387873, 389884, 391871, 393893, 395885, 397877, 399879, 401881, 403878, 405892, 407899, 409880, 411899, 413869, 415893, 417875, 441798, 443801, 445815, 447807, 449836, 451794, 453804, 455807, 457805, 459795, 461797, 463801, 465806, 467790, 469790, 471809, 473808, 475804, 477797, 479805, 481812, 483816, 485809, 487805, 489795, 491812, 493788, 495817, 497805, 499788, 501789, 503824]\n",
    "\n",
    "        # then our slices will be : [0:903697, 903698 : 905674, 905675 : 907668,etc]\n",
    "\n",
    "        # the unique events we have are 5  7  8  1  3  4  9 11 12 10 13 15 16 14\n",
    "\n",
    "        slices = [(start_indices[i], start_indices[i + 1] - 1) for i in range(len(start_indices) - 1)]\n",
    "        # Include the final slice\n",
    "        slices.append((start_indices[-1], 'end')) \n",
    "        print(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec694fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
