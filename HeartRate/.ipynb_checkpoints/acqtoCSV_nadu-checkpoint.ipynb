{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a908878b",
   "metadata": {},
   "source": [
    "# ACQ to CSV \n",
    "\n",
    "Before running this file make sure all the acq files are organized and named properly and are on the NasDrive (or somewhere). To run from the NasDrive make sure to be connected to Psychsecure or campus VPN. \n",
    "\n",
    "Thie script assumes that subject and run are in the file name like this: \n",
    "fmcc_sub47_task_0001.acq \n",
    "\n",
    "This is Subject 47, Run 1. The runs go from 0 to 8, later in the pipeline this will be converted to Run 1 to 9.  \n",
    "\n",
    "The full ReadMe and How-To Guide is located here: \n",
    "https://docs.google.com/document/d/1hfkKuHdc5htsAZjkRZWYzMZev2CSRcb4WBH9agrphzE/edit?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7ee412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import these libraries (make sure they are installed before)\n",
    "import bioread\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bd7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional first step - scan the data structure\n",
    "# By seeing the data structure we can modify the script accordingly. \n",
    "# Each ACQ template may have a slightly different structure - different channels used in physio collection means different columns in the DF \n",
    "\n",
    "# use the bioread function on one acq file- this gives us an idea of what it looks like  \n",
    "acq_dataset = bioread.read_file(\"/Volumes/labshare/Nadu/fmcc_winter_spring_quarter/sub49/fmcc_sub49_task_0000.acq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8168fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# check how many columns in this dataset\n",
    "# important for later in the code when creating a dataframe\n",
    "num_cols = len(acq_dataset.channels)\n",
    "print(num_cols)\n",
    " \n",
    "#12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112dcca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GSR - EDA100C  ECG - ECG100C  Feedback Cable - CBLCFMA - Current Feed  \\\n",
      "count  636005.000000  636005.000000                            636005.000000   \n",
      "mean       34.670380      -0.018868                                 0.313640   \n",
      "std         1.983866       0.449828                                 0.134834   \n",
      "min        31.568908      -2.791443                               -18.667603   \n",
      "25%        33.158874      -0.207214                                 0.302124   \n",
      "50%        34.268188      -0.062866                                 0.314331   \n",
      "75%        36.088561       0.216064                                 0.326538   \n",
      "max        39.703368       2.732544                                19.247437   \n",
      "\n",
      "       Stim - Custom, AMI / HLT - A16  Digital (STP Input 0)  \\\n",
      "count                   636005.000000          636005.000000   \n",
      "mean                        -0.198731               0.010849   \n",
      "std                          0.140506               0.232653   \n",
      "min                         -0.217586               0.000000   \n",
      "25%                         -0.206295               0.000000   \n",
      "50%                         -0.204159               0.000000   \n",
      "75%                         -0.202327               0.000000   \n",
      "max                          4.684965               5.000000   \n",
      "\n",
      "       Digital (STP Input 1)  Digital (STP Input 2)  Digital (STP Input 3)  \\\n",
      "count          636005.000000          636005.000000          636005.000000   \n",
      "mean                0.005189               0.010692               0.000943   \n",
      "std                 0.160985               0.230964               0.068674   \n",
      "min                 0.000000               0.000000               0.000000   \n",
      "25%                 0.000000               0.000000               0.000000   \n",
      "50%                 0.000000               0.000000               0.000000   \n",
      "75%                 0.000000               0.000000               0.000000   \n",
      "max                 5.000000               5.000000               5.000000   \n",
      "\n",
      "       Digital (STP Input 4)  Digital (STP Input 5)  Digital (STP Input 6)  \\\n",
      "count          636005.000000          636005.000000          636005.000000   \n",
      "mean                0.019811               0.000629               0.020126   \n",
      "std                 0.314107               0.056074               0.316581   \n",
      "min                 0.000000               0.000000               0.000000   \n",
      "25%                 0.000000               0.000000               0.000000   \n",
      "50%                 0.000000               0.000000               0.000000   \n",
      "75%                 0.000000               0.000000               0.000000   \n",
      "max                 5.000000               5.000000               5.000000   \n",
      "\n",
      "       Digital (STP Input 7)  \n",
      "count          636005.000000  \n",
      "mean                0.005346  \n",
      "std                 0.163404  \n",
      "min                 0.000000  \n",
      "25%                 0.000000  \n",
      "50%                 0.000000  \n",
      "75%                 0.000000  \n",
      "max                 5.000000  \n"
     ]
    }
   ],
   "source": [
    "# explore the data and scan the structure. \n",
    "# optional step: export a csv of this structure \n",
    "\n",
    "data = {}\n",
    "for channel in acq_dataset.channels:\n",
    "    data[channel.name] = channel.data  # Use channel names as column headers\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display basic statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "#output_path = \"/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/fmcc_w25/fmcc_csv\"\n",
    "#df.to_csv(output_path, index=False, header=True)\n",
    "#print(f\"DataFrame successfully exported to {output_path}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc26678e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSR - EDA100C</th>\n",
       "      <th>ECG - ECG100C</th>\n",
       "      <th>Feedback Cable - CBLCFMA - Current Feed</th>\n",
       "      <th>Stim - Custom, AMI / HLT - A16</th>\n",
       "      <th>Digital (STP Input 0)</th>\n",
       "      <th>Digital (STP Input 1)</th>\n",
       "      <th>Digital (STP Input 2)</th>\n",
       "      <th>Digital (STP Input 3)</th>\n",
       "      <th>Digital (STP Input 4)</th>\n",
       "      <th>Digital (STP Input 5)</th>\n",
       "      <th>Digital (STP Input 6)</th>\n",
       "      <th>Digital (STP Input 7)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.477660</td>\n",
       "      <td>-0.157776</td>\n",
       "      <td>0.329590</td>\n",
       "      <td>-0.204464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.480712</td>\n",
       "      <td>-0.149841</td>\n",
       "      <td>0.302124</td>\n",
       "      <td>-0.202022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.480712</td>\n",
       "      <td>-0.142822</td>\n",
       "      <td>0.311279</td>\n",
       "      <td>-0.201412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.476134</td>\n",
       "      <td>-0.136414</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>-0.205074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.474608</td>\n",
       "      <td>-0.128784</td>\n",
       "      <td>0.311279</td>\n",
       "      <td>-0.203548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.479186</td>\n",
       "      <td>-0.123901</td>\n",
       "      <td>0.311279</td>\n",
       "      <td>-0.204769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.480712</td>\n",
       "      <td>-0.118713</td>\n",
       "      <td>0.286865</td>\n",
       "      <td>-0.201717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.474608</td>\n",
       "      <td>-0.113831</td>\n",
       "      <td>0.265503</td>\n",
       "      <td>-0.200802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.479186</td>\n",
       "      <td>-0.108643</td>\n",
       "      <td>0.277710</td>\n",
       "      <td>-0.206295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.474608</td>\n",
       "      <td>-0.104675</td>\n",
       "      <td>0.296021</td>\n",
       "      <td>-0.204464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GSR - EDA100C  ECG - ECG100C  Feedback Cable - CBLCFMA - Current Feed  \\\n",
       "0      36.477660      -0.157776                                 0.329590   \n",
       "1      36.480712      -0.149841                                 0.302124   \n",
       "2      36.480712      -0.142822                                 0.311279   \n",
       "3      36.476134      -0.136414                                 0.320435   \n",
       "4      36.474608      -0.128784                                 0.311279   \n",
       "5      36.479186      -0.123901                                 0.311279   \n",
       "6      36.480712      -0.118713                                 0.286865   \n",
       "7      36.474608      -0.113831                                 0.265503   \n",
       "8      36.479186      -0.108643                                 0.277710   \n",
       "9      36.474608      -0.104675                                 0.296021   \n",
       "\n",
       "   Stim - Custom, AMI / HLT - A16  Digital (STP Input 0)  \\\n",
       "0                       -0.204464                    0.0   \n",
       "1                       -0.202022                    0.0   \n",
       "2                       -0.201412                    0.0   \n",
       "3                       -0.205074                    0.0   \n",
       "4                       -0.203548                    0.0   \n",
       "5                       -0.204769                    0.0   \n",
       "6                       -0.201717                    0.0   \n",
       "7                       -0.200802                    0.0   \n",
       "8                       -0.206295                    0.0   \n",
       "9                       -0.204464                    0.0   \n",
       "\n",
       "   Digital (STP Input 1)  Digital (STP Input 2)  Digital (STP Input 3)  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "5                    0.0                    0.0                    0.0   \n",
       "6                    0.0                    0.0                    0.0   \n",
       "7                    0.0                    0.0                    0.0   \n",
       "8                    0.0                    0.0                    0.0   \n",
       "9                    0.0                    0.0                    0.0   \n",
       "\n",
       "   Digital (STP Input 4)  Digital (STP Input 5)  Digital (STP Input 6)  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "5                    0.0                    0.0                    0.0   \n",
       "6                    0.0                    0.0                    0.0   \n",
       "7                    0.0                    0.0                    0.0   \n",
       "8                    0.0                    0.0                    0.0   \n",
       "9                    0.0                    0.0                    0.0   \n",
       "\n",
       "   Digital (STP Input 7)  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "5                    0.0  \n",
       "6                    0.0  \n",
       "7                    0.0  \n",
       "8                    0.0  \n",
       "9                    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10 rows \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48d06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths to the folder you want to list\n",
    "\n",
    "# Input path should be folder where all the acq files are located \n",
    "# This is the path to Nasdrive folder \n",
    "biopacpath = \"/Volumes/labshare/Nadu/fmcc_winter_spring_quarter\"\n",
    "\n",
    "\n",
    "# path to output the csv files - make sure there is no final slash. \n",
    "# os.path.join is used later - it expects no final slash \n",
    "# outputdir = '/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/fmcc_w25/fmcc_csv'\n",
    "outputdir = \"/Users/nadezhdabarbashova/Documents/fmcc_heart_rate/raw_csv\"\n",
    "\n",
    "# list of subjects. Have them as character formats \n",
    "# make sure to check conventions like adding a 0 before \n",
    "\n",
    "subjects = [\"49\", \"50\", \"51\", \"52\", \"54\", \"55\", \"56\", \"57\", \"58\", \"61\", \"62\", \"63\", \"65\", \"67\",\n",
    "            \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"76\", \"78\", \"81\", \"82\", \"84\", \"85\", \"87\",\n",
    "           \"88\", \"89\", \"91\", \"93\", \"98\", \"99\", \"100\", \"104\", \n",
    "             \"107\", \"109\", \"110\"]\n",
    "\n",
    "subjects = [\"70\", \"71\", \"72\", \"73\", \"74\", \"76\", \"78\", \"81\", \"82\", \"84\", \"85\", \"87\",\n",
    "           \"88\", \"89\", \"91\", \"93\", \"98\", \"99\", \"100\", \"104\", \n",
    "             \"107\", \"109\", \"110\"]\n",
    "\n",
    "# remove this if it exists: \n",
    "# subjects.remove(\".DS_Store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaccf62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: 49\n",
      "Processing file: fmcc_sub49_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub49_task_0000.acq\n",
      "Processing file: fmcc_sub49_task_0001.acq\n",
      "done creating csv for fmcc_sub49_task_0001.acq\n",
      "Processing file: fmcc_sub49_task_0002.acq\n",
      "done creating csv for fmcc_sub49_task_0002.acq\n",
      "Processing file: fmcc_sub49_task_0003.acq\n",
      "done creating csv for fmcc_sub49_task_0003.acq\n",
      "Processing file: fmcc_sub49_task_0004.acq\n",
      "done creating csv for fmcc_sub49_task_0004.acq\n",
      "Processing file: fmcc_sub49_task_0005.acq\n",
      "done creating csv for fmcc_sub49_task_0005.acq\n",
      "Processing file: fmcc_sub49_task_0006.acq\n",
      "done creating csv for fmcc_sub49_task_0006.acq\n",
      "Processing file: fmcc_sub49_task_0007.acq\n",
      "done creating csv for fmcc_sub49_task_0007.acq\n",
      "Processing file: fmcc_sub49_task_0008.acq\n",
      "done creating csv for fmcc_sub49_task_0008.acq\n",
      "Processing subject: 50\n",
      "Processing file: fmcc_sub50_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub50_task_0000.acq\n",
      "Processing file: fmcc_sub50_task_0001.acq\n",
      "done creating csv for fmcc_sub50_task_0001.acq\n",
      "Processing file: fmcc_sub50_task_0002.acq\n",
      "done creating csv for fmcc_sub50_task_0002.acq\n",
      "Processing file: fmcc_sub50_task_0003.acq\n",
      "done creating csv for fmcc_sub50_task_0003.acq\n",
      "Processing file: fmcc_sub50_task_0004.acq\n",
      "done creating csv for fmcc_sub50_task_0004.acq\n",
      "Processing file: fmcc_sub50_task_0005.acq\n",
      "done creating csv for fmcc_sub50_task_0005.acq\n",
      "Processing file: fmcc_sub50_task_0006.acq\n",
      "done creating csv for fmcc_sub50_task_0006.acq\n",
      "Processing file: fmcc_sub50_task_0007.acq\n",
      "done creating csv for fmcc_sub50_task_0007.acq\n",
      "Processing file: fmcc_sub50_task_0008.acq\n",
      "done creating csv for fmcc_sub50_task_0008.acq\n",
      "Processing subject: 51\n",
      "Processing file: fmcc_sub51_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub51_task_0000.acq\n",
      "Processing file: fmcc_sub51_task_0001.acq\n",
      "done creating csv for fmcc_sub51_task_0001.acq\n",
      "Processing file: fmcc_sub51_task_0002.acq\n",
      "done creating csv for fmcc_sub51_task_0002.acq\n",
      "Processing file: fmcc_sub51_task_0003.acq\n",
      "done creating csv for fmcc_sub51_task_0003.acq\n",
      "Processing file: fmcc_sub51_task_0004.acq\n",
      "done creating csv for fmcc_sub51_task_0004.acq\n",
      "Processing file: fmcc_sub51_task_0005.acq\n",
      "done creating csv for fmcc_sub51_task_0005.acq\n",
      "Processing file: fmcc_sub51_task_0006.acq\n",
      "done creating csv for fmcc_sub51_task_0006.acq\n",
      "Processing file: fmcc_sub51_task_0007.acq\n",
      "done creating csv for fmcc_sub51_task_0007.acq\n",
      "Processing file: fmcc_sub51_task_0008.acq\n",
      "done creating csv for fmcc_sub51_task_0008.acq\n",
      "Processing subject: 52\n",
      "Processing file: fmcc_sub52_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub52_task_0000.acq\n",
      "Processing file: fmcc_sub52_task_0001.acq\n",
      "done creating csv for fmcc_sub52_task_0001.acq\n",
      "Processing file: fmcc_sub52_task_0002.acq\n",
      "done creating csv for fmcc_sub52_task_0002.acq\n",
      "Processing file: fmcc_sub52_task_0003.acq\n",
      "done creating csv for fmcc_sub52_task_0003.acq\n",
      "Processing file: fmcc_sub52_task_0004.acq\n",
      "done creating csv for fmcc_sub52_task_0004.acq\n",
      "Processing file: fmcc_sub52_task_0005.acq\n",
      "done creating csv for fmcc_sub52_task_0005.acq\n",
      "Processing file: fmcc_sub52_task_0006.acq\n",
      "done creating csv for fmcc_sub52_task_0006.acq\n",
      "Processing file: fmcc_sub52_task_0007.acq\n",
      "done creating csv for fmcc_sub52_task_0007.acq\n",
      "Processing file: fmcc_sub52_task_0008.acq\n",
      "done creating csv for fmcc_sub52_task_0008.acq\n",
      "Processing subject: 54\n",
      "Processing file: fmcc_sub54_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub54_task_0000.acq\n",
      "Processing file: fmcc_sub54_task_0001.acq\n",
      "done creating csv for fmcc_sub54_task_0001.acq\n",
      "Processing file: fmcc_sub54_task_0002.acq\n",
      "done creating csv for fmcc_sub54_task_0002.acq\n",
      "Processing file: fmcc_sub54_task_0003.acq\n",
      "done creating csv for fmcc_sub54_task_0003.acq\n",
      "Processing file: fmcc_sub54_task_0004.acq\n",
      "done creating csv for fmcc_sub54_task_0004.acq\n",
      "Processing file: fmcc_sub54_task_0005.acq\n",
      "done creating csv for fmcc_sub54_task_0005.acq\n",
      "Processing file: fmcc_sub54_task_0006.acq\n",
      "done creating csv for fmcc_sub54_task_0006.acq\n",
      "Processing file: fmcc_sub54_task_0007.acq\n",
      "done creating csv for fmcc_sub54_task_0007.acq\n",
      "Processing file: fmcc_sub54_task_0008.acq\n",
      "done creating csv for fmcc_sub54_task_0008.acq\n",
      "Processing subject: 55\n",
      "Processing file: fmcc_sub55_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub55_task_0000.acq\n",
      "Processing file: fmcc_sub55_task_0001.acq\n",
      "done creating csv for fmcc_sub55_task_0001.acq\n",
      "Processing file: fmcc_sub55_task_0002.acq\n",
      "done creating csv for fmcc_sub55_task_0002.acq\n",
      "Processing file: fmcc_sub55_task_0003.acq\n",
      "done creating csv for fmcc_sub55_task_0003.acq\n",
      "Processing file: fmcc_sub55_task_0004.acq\n",
      "done creating csv for fmcc_sub55_task_0004.acq\n",
      "Processing file: fmcc_sub55_task_0005.acq\n",
      "done creating csv for fmcc_sub55_task_0005.acq\n",
      "Processing file: fmcc_sub55_task_0006.acq\n",
      "done creating csv for fmcc_sub55_task_0006.acq\n",
      "Processing file: fmcc_sub55_task_0007.acq\n",
      "done creating csv for fmcc_sub55_task_0007.acq\n",
      "Processing file: fmcc_sub55_task_0008.acq\n",
      "done creating csv for fmcc_sub55_task_0008.acq\n",
      "Processing subject: 56\n",
      "Processing file: fmcc_sub56_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub56_task_0000.acq\n",
      "Processing file: fmcc_sub56_task_0001.acq\n",
      "done creating csv for fmcc_sub56_task_0001.acq\n",
      "Processing file: fmcc_sub56_task_0002.acq\n",
      "done creating csv for fmcc_sub56_task_0002.acq\n",
      "Processing file: fmcc_sub56_task_0003.acq\n",
      "done creating csv for fmcc_sub56_task_0003.acq\n",
      "Processing file: fmcc_sub56_task_0004.acq\n",
      "done creating csv for fmcc_sub56_task_0004.acq\n",
      "Processing file: fmcc_sub56_task_0005.acq\n",
      "done creating csv for fmcc_sub56_task_0005.acq\n",
      "Processing file: fmcc_sub56_task_0006.acq\n",
      "done creating csv for fmcc_sub56_task_0006.acq\n",
      "Processing file: fmcc_sub56_task_0007.acq\n",
      "done creating csv for fmcc_sub56_task_0007.acq\n",
      "Processing file: fmcc_sub56_task_0008.acq\n",
      "done creating csv for fmcc_sub56_task_0008.acq\n",
      "Processing subject: 57\n",
      "Processing file: fmcc_sub57_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub57_task_0000.acq\n",
      "Processing file: fmcc_sub57_task_0001.acq\n",
      "done creating csv for fmcc_sub57_task_0001.acq\n",
      "Processing file: fmcc_sub57_task_0002.acq\n",
      "done creating csv for fmcc_sub57_task_0002.acq\n",
      "Processing file: fmcc_sub57_task_0003.acq\n",
      "done creating csv for fmcc_sub57_task_0003.acq\n",
      "Processing file: fmcc_sub57_task_0004.acq\n",
      "done creating csv for fmcc_sub57_task_0004.acq\n",
      "Processing file: fmcc_sub57_task_0005.acq\n",
      "done creating csv for fmcc_sub57_task_0005.acq\n",
      "Processing file: fmcc_sub57_task_0006.acq\n",
      "done creating csv for fmcc_sub57_task_0006.acq\n",
      "Processing file: fmcc_sub57_task_0007.acq\n",
      "done creating csv for fmcc_sub57_task_0007.acq\n",
      "Processing file: fmcc_sub57_task_0008.acq\n",
      "done creating csv for fmcc_sub57_task_0008.acq\n",
      "Processing subject: 58\n",
      "Processing file: fmcc_sub58_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub58_task_0000.acq\n",
      "Processing file: fmcc_sub58_task_0001.acq\n",
      "done creating csv for fmcc_sub58_task_0001.acq\n",
      "Processing file: fmcc_sub58_task_0002.acq\n",
      "done creating csv for fmcc_sub58_task_0002.acq\n",
      "Processing file: fmcc_sub58_task_0003.acq\n",
      "done creating csv for fmcc_sub58_task_0003.acq\n",
      "Processing file: fmcc_sub58_task_0004.acq\n",
      "done creating csv for fmcc_sub58_task_0004.acq\n",
      "Processing file: fmcc_sub58_task_0005.acq\n",
      "done creating csv for fmcc_sub58_task_0005.acq\n",
      "Processing file: fmcc_sub58_task_0006.acq\n",
      "done creating csv for fmcc_sub58_task_0006.acq\n",
      "Processing file: fmcc_sub58_task_0007.acq\n",
      "done creating csv for fmcc_sub58_task_0007.acq\n",
      "Processing file: fmcc_sub58_task_0008.acq\n",
      "done creating csv for fmcc_sub58_task_0008.acq\n",
      "Processing subject: 61\n",
      "Processing file: fmcc_sub61_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub61_task_0000.acq\n",
      "Processing file: fmcc_sub61_task_0001.acq\n",
      "done creating csv for fmcc_sub61_task_0001.acq\n",
      "Processing file: fmcc_sub61_task_0002.acq\n",
      "done creating csv for fmcc_sub61_task_0002.acq\n",
      "Processing file: fmcc_sub61_task_0003.acq\n",
      "done creating csv for fmcc_sub61_task_0003.acq\n",
      "Processing file: fmcc_sub61_task_0004.acq\n",
      "done creating csv for fmcc_sub61_task_0004.acq\n",
      "Processing file: fmcc_sub61_task_0005.acq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done creating csv for fmcc_sub61_task_0005.acq\n",
      "Processing file: fmcc_sub61_task_0006.acq\n",
      "done creating csv for fmcc_sub61_task_0006.acq\n",
      "Processing file: fmcc_sub61_task_0007.acq\n",
      "done creating csv for fmcc_sub61_task_0007.acq\n",
      "Processing file: fmcc_sub61_task_0008.acq\n",
      "done creating csv for fmcc_sub61_task_0008.acq\n",
      "Processing subject: 62\n",
      "Processing file: fmcc_sub62_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub62_task_0000.acq\n",
      "Processing file: fmcc_sub62_task_0001.acq\n",
      "done creating csv for fmcc_sub62_task_0001.acq\n",
      "Processing file: fmcc_sub62_task_0002.acq\n",
      "done creating csv for fmcc_sub62_task_0002.acq\n",
      "Processing file: fmcc_sub62_task_0003.acq\n",
      "done creating csv for fmcc_sub62_task_0003.acq\n",
      "Processing file: fmcc_sub62_task_0004.acq\n",
      "done creating csv for fmcc_sub62_task_0004.acq\n",
      "Processing file: fmcc_sub62_task_0005.acq\n",
      "done creating csv for fmcc_sub62_task_0005.acq\n",
      "Processing file: fmcc_sub62_task_0006.acq\n",
      "done creating csv for fmcc_sub62_task_0006.acq\n",
      "Processing file: fmcc_sub62_task_0007.acq\n",
      "done creating csv for fmcc_sub62_task_0007.acq\n",
      "Processing file: fmcc_sub62_task_0008.acq\n",
      "done creating csv for fmcc_sub62_task_0008.acq\n",
      "Processing subject: 63\n",
      "Processing file: fmcc_sub63_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub63_task_0000.acq\n",
      "Processing file: fmcc_sub63_task_0001.acq\n",
      "done creating csv for fmcc_sub63_task_0001.acq\n",
      "Processing file: fmcc_sub63_task_0002.acq\n",
      "done creating csv for fmcc_sub63_task_0002.acq\n",
      "Processing file: fmcc_sub63_task_0003.acq\n",
      "done creating csv for fmcc_sub63_task_0003.acq\n",
      "Processing file: fmcc_sub63_task_0004.acq\n",
      "done creating csv for fmcc_sub63_task_0004.acq\n",
      "Processing file: fmcc_sub63_task_0005.acq\n",
      "done creating csv for fmcc_sub63_task_0005.acq\n",
      "Processing file: fmcc_sub63_task_0006.acq\n",
      "done creating csv for fmcc_sub63_task_0006.acq\n",
      "Processing file: fmcc_sub63_task_0007.acq\n",
      "done creating csv for fmcc_sub63_task_0007.acq\n",
      "Processing file: fmcc_sub63_task_0008.acq\n",
      "done creating csv for fmcc_sub63_task_0008.acq\n",
      "Processing subject: 65\n",
      "Processing file: fmcc_sub65_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub65_task_0000.acq\n",
      "Processing file: fmcc_sub65_task_0001.acq\n",
      "done creating csv for fmcc_sub65_task_0001.acq\n",
      "Processing file: fmcc_sub65_task_0002.acq\n",
      "done creating csv for fmcc_sub65_task_0002.acq\n",
      "Processing file: fmcc_sub65_task_0003.acq\n",
      "done creating csv for fmcc_sub65_task_0003.acq\n",
      "Processing file: fmcc_sub65_task_0004.acq\n",
      "done creating csv for fmcc_sub65_task_0004.acq\n",
      "Processing file: fmcc_sub65_task_0005.acq\n",
      "done creating csv for fmcc_sub65_task_0005.acq\n",
      "Processing file: fmcc_sub65_task_0006.acq\n",
      "done creating csv for fmcc_sub65_task_0006.acq\n",
      "Processing file: fmcc_sub65_task_0007.acq\n",
      "done creating csv for fmcc_sub65_task_0007.acq\n",
      "Processing file: fmcc_sub65_task_0008.acq\n",
      "done creating csv for fmcc_sub65_task_0008.acq\n",
      "Processing subject: 67\n",
      "Processing file: fmcc_sub67_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub67_task_0000.acq\n",
      "Processing file: fmcc_sub67_task_0001.acq\n",
      "done creating csv for fmcc_sub67_task_0001.acq\n",
      "Processing file: fmcc_sub67_task_0002.acq\n",
      "done creating csv for fmcc_sub67_task_0002.acq\n",
      "Processing file: fmcc_sub67_task_0003.acq\n",
      "done creating csv for fmcc_sub67_task_0003.acq\n",
      "Processing file: fmcc_sub67_task_0004.acq\n",
      "done creating csv for fmcc_sub67_task_0004.acq\n",
      "Processing file: fmcc_sub67_task_0005.acq\n",
      "done creating csv for fmcc_sub67_task_0005.acq\n",
      "Processing file: fmcc_sub67_task_0006.acq\n",
      "done creating csv for fmcc_sub67_task_0006.acq\n",
      "Processing file: fmcc_sub67_task_0007.acq\n",
      "done creating csv for fmcc_sub67_task_0007.acq\n",
      "Processing file: fmcc_sub67_task_0008.acq\n",
      "done creating csv for fmcc_sub67_task_0008.acq\n",
      "Processing subject: 68\n",
      "Processing file: fmcc_sub68_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub68_task_0000.acq\n",
      "Processing file: fmcc_sub68_task_0001.acq\n",
      "done creating csv for fmcc_sub68_task_0001.acq\n",
      "Processing file: fmcc_sub68_task_0002.acq\n",
      "done creating csv for fmcc_sub68_task_0002.acq\n",
      "Processing file: fmcc_sub68_task_0003.acq\n",
      "done creating csv for fmcc_sub68_task_0003.acq\n",
      "Processing file: fmcc_sub68_task_0004.acq\n",
      "done creating csv for fmcc_sub68_task_0004.acq\n",
      "Processing file: fmcc_sub68_task_0005.acq\n",
      "done creating csv for fmcc_sub68_task_0005.acq\n",
      "Processing file: fmcc_sub68_task_0006.acq\n",
      "done creating csv for fmcc_sub68_task_0006.acq\n",
      "Processing file: fmcc_sub68_task_0007.acq\n",
      "done creating csv for fmcc_sub68_task_0007.acq\n",
      "Processing file: fmcc_sub68_task_0008.acq\n",
      "done creating csv for fmcc_sub68_task_0008.acq\n",
      "Processing subject: 69\n",
      "Processing file: fmcc_sub69_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub69_task_0000.acq\n",
      "Processing file: fmcc_sub69_task_0001.acq\n",
      "done creating csv for fmcc_sub69_task_0001.acq\n",
      "Processing file: fmcc_sub69_task_0002.acq\n",
      "done creating csv for fmcc_sub69_task_0002.acq\n",
      "Processing file: fmcc_sub69_task_0003.acq\n",
      "done creating csv for fmcc_sub69_task_0003.acq\n",
      "Processing file: fmcc_sub69_task_0004.acq\n",
      "done creating csv for fmcc_sub69_task_0004.acq\n",
      "Processing file: fmcc_sub69_task_0005.acq\n",
      "done creating csv for fmcc_sub69_task_0005.acq\n",
      "Processing file: fmcc_sub69_task_0006.acq\n",
      "done creating csv for fmcc_sub69_task_0006.acq\n",
      "Processing file: fmcc_sub69_task_0007.acq\n",
      "done creating csv for fmcc_sub69_task_0007.acq\n",
      "Processing file: fmcc_sub69_task_0008.acq\n",
      "done creating csv for fmcc_sub69_task_0008.acq\n",
      "Processing subject: 70\n",
      "Processing file: fmcc_sub70_task_0000.acq\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m fn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(inputdir, inputfn)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# there are only 12 channels. use bioread to extract info from each channel \u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# rename them to go from 1 to 12 instead of 0 to 11 \u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m acq_dataset \u001b[38;5;241m=\u001b[39m bioread\u001b[38;5;241m.\u001b[39mread_file(fn)\n\u001b[1;32m     32\u001b[0m chan1 \u001b[38;5;241m=\u001b[39m acq_dataset\u001b[38;5;241m.\u001b[39mchannels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata \n\u001b[1;32m     33\u001b[0m chan2 \u001b[38;5;241m=\u001b[39m acq_dataset\u001b[38;5;241m.\u001b[39mchannels[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bioread/__init__.py:26\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filelike, channel_indexes)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(filelike, channel_indexes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    Read a file (either an IO object or a filename) and return a Datafile.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    target_chunk_size:  A guide for the number of bytes to read at a time.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mReader\u001b[38;5;241m.\u001b[39mread(filelike, channel_indexes)\u001b[38;5;241m.\u001b[39mdatafile\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bioread/reader.py:86\u001b[0m, in \u001b[0;36mReader.read\u001b[0;34m(cls, fo, channel_indexes, target_chunk_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(io)\n\u001b[1;32m     85\u001b[0m     reader\u001b[38;5;241m.\u001b[39m_read_headers()\n\u001b[0;32m---> 86\u001b[0m     reader\u001b[38;5;241m.\u001b[39m_read_data(channel_indexes, target_chunk_size)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reader\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bioread/reader.py:289\u001b[0m, in \u001b[0;36mReader._read_data\u001b[0;34m(self, channel_indexes, target_chunk_size)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__read_data_compressed(channel_indexes)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__read_data_uncompressed(channel_indexes, target_chunk_size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bioread/reader.py:354\u001b[0m, in \u001b[0;36mReader.__read_data_uncompressed\u001b[0;34m(self, channel_indexes, target_chunk_size)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_start_offset)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# This will fill self.datafile.channels with data.\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m read_uncompressed(\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_file,\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatafile\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m    357\u001b[0m     channel_indexes,\n\u001b[1;32m    358\u001b[0m     target_chunk_size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bioread/reader.py:462\u001b[0m, in \u001b[0;36mread_uncompressed\u001b[0;34m(f, channels, channel_indexes, target_chunk_size)\u001b[0m\n\u001b[1;32m    458\u001b[0m     channels[i]\u001b[38;5;241m.\u001b[39m_allocate_raw_data()\n\u001b[1;32m    460\u001b[0m chunker \u001b[38;5;241m=\u001b[39m make_chunk_reader(\n\u001b[1;32m    461\u001b[0m     f, channels, channel_indexes, target_chunk_size)\n\u001b[0;32m--> 462\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_buffers \u001b[38;5;129;01min\u001b[39;00m chunker:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m channel_indexes:\n\u001b[1;32m    464\u001b[0m         ch \u001b[38;5;241m=\u001b[39m channels[i]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bioread/reader.py:501\u001b[0m, in \u001b[0;36mread_chunks\u001b[0;34m(f, buffers, byte_pattern, channel_indexes)\u001b[0m\n\u001b[1;32m    497\u001b[0m chunk_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pat)\n\u001b[1;32m    498\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChunk \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m bytes at \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    499\u001b[0m     chunk_number, chunk_bytes, f\u001b[38;5;241m.\u001b[39mtell()))\n\u001b[1;32m    500\u001b[0m chunk_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(\n\u001b[0;32m--> 501\u001b[0m     f\u001b[38;5;241m.\u001b[39mread(chunk_bytes), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, count\u001b[38;5;241m=\u001b[39mchunk_bytes)\n\u001b[1;32m    502\u001b[0m update_buffers_with_data(\n\u001b[1;32m    503\u001b[0m     chunk_data, buffers, pat, channel_indexes)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m buffers\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for sub in subjects:\n",
    "#Below convert the acq files to matlab files\n",
    "    inputdir = biopacpath + \"/sub\" + sub\n",
    "    allfiles = os.listdir(inputdir)\n",
    "    #print(f\"Files in directory {inputdir}: {allfiles}\")  # Debugging: list files\n",
    "\n",
    "    #Get the acq file names that only task related\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(inputdir):\n",
    "        print(f\"Directory does not exist: {inputdir}\")\n",
    "        continue  # Skip this subject if directory doesn't exist\n",
    "\n",
    "    print(f\"Processing subject: {sub}\")  # Debugging: confirm subject being processed\n",
    "    #print(f\"directory: {inputdir}\")\n",
    "\n",
    "    # Find prefix for fmcc \n",
    "    # Then get task-related .acq files - must end with acq, must have task (no physio)\n",
    "     \n",
    "    taskfnli = [item for item in allfiles if item.endswith('.acq') and 'task' in item]\n",
    "    \n",
    "    #print(f\"Task-related files: {taskfnli}\")  # Debugging: check filtered files\n",
    "    \n",
    "    for inputfn in taskfnli:\n",
    "        print(f\"Processing file: {inputfn}\")\n",
    "        \n",
    "        # filename = main directory + filename of this acq file \n",
    "        fn = os.path.join(inputdir, inputfn)\n",
    "    \n",
    "        # there are only 12 channels. use bioread to extract info from each channel \n",
    "        # rename them to go from 1 to 12 instead of 0 to 11 \n",
    "        acq_dataset = bioread.read_file(fn)\n",
    "        chan1 = acq_dataset.channels[0].data \n",
    "        chan2 = acq_dataset.channels[1].data\n",
    "        chan3 = acq_dataset.channels[2].data\n",
    "        chan4 = acq_dataset.channels[3].data\n",
    "        chan5 = acq_dataset.channels[4].data\n",
    "        chan6 = acq_dataset.channels[5].data\n",
    "        chan7 = acq_dataset.channels[6].data\n",
    "        chan8 = acq_dataset.channels[7].data\n",
    "        chan9 = acq_dataset.channels[8].data\n",
    "        chan10 = acq_dataset.channels[9].data\n",
    "        chan11 = acq_dataset.channels[10].data\n",
    "        chan12 = acq_dataset.channels[11].data\n",
    "\n",
    "        # make a dataframe by combining these channels \n",
    "        df = pd.DataFrame({\"1\": chan1, \"2\": chan2, \"3\": chan3, \"4\": chan4, \"5\": chan5, \n",
    "                   \"6\": chan6, \"7\": chan7, \"8\": chan8, \"9\": chan9, \"10\": chan10, \n",
    "                   \"11\": chan11, \"12\": chan12})\n",
    "\n",
    "        # if you want to see the structure at this stage - print first 10 rows: \n",
    "        # df.head(10)\n",
    "        \n",
    "        #create output sub-directory for this subject - main directory + sub## \n",
    "        outputsubdir = outputdir + \"/sub\" + sub\n",
    "        \n",
    "        #if the folder is not found - create a folder \n",
    "        if not os.path.exists(outputsubdir):\n",
    "            \n",
    "            # If it doesn't exist, create the folder\n",
    "            print(\"folder not found - will be created\")\n",
    "            os.makedirs(outputsubdir)   \n",
    "            #mat_fn = inputfn.replace(\".acq\", \".mat\")\n",
    "        \n",
    "        # copy the acq filename but now end it with .csv \n",
    "        csv_fn = inputfn.replace(\".acq\", \".csv\")\n",
    "              \n",
    "        # construct and output file path from filename and output directory    \n",
    "        csv_file = os.path.join(outputsubdir, csv_fn)\n",
    " \n",
    "        # Save the NumPy array to a MATLAB file\n",
    "        #savemat(mat_file, {'data': df.to_numpy()})\n",
    "            \n",
    "        # turn the df into a csv file and save it to the csv file directory \n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"done creating csv for {inputfn}\")\n",
    "        \n",
    "        \n",
    "print(\"done processing all subjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below just to get the sample rate  \n",
    "# EDASampleRate.append(acq_dataset.channels[0].samples_per_second)\n",
    "# TrigerSampleRate.append(acq_dataset.channels[2].samples_per_second)\n",
    "# make dataframe and save\n",
    "# sampleRdf = pd.DataFrame({\"participant\": subli, \"run\": runli, \"EDASampleRate\": EDASampleRate, \"TrigerSampleRate\":TrigerSampleRate})\n",
    "# sampleRdf.to_csv(\"/Users/jingyiwang/Dropbox/LEAP_Neuro_Lab/researchProjects/jingyi_documents/emotion_motor_grant/AA_fMRIAnalyses/EDAAnalysis/SampleRate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae6f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/fmcc_w25/acq_data\n"
     ]
    }
   ],
   "source": [
    "print(biopacpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e33da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b88682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe4a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d598a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05703ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
