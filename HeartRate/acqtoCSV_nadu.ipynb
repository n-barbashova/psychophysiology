{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ff0e59",
   "metadata": {},
   "source": [
    "# ACQ to CSV \n",
    "\n",
    "Before running this file make sure all the acq files are organized and named properly and are on the NasDrive (or somewhere). To run from the NasDrive make sure to be connected to Psychsecure or campus VPN. \n",
    "\n",
    "Thie script assumes that subject and run are in the file name like this: \n",
    "fmcc_sub47_task_0001.acq \n",
    "\n",
    "This is Subject 47, Run 1. The runs go from 0 to 8, later in the pipeline this will be converted to Run 1 to 9.  \n",
    "\n",
    "The full ReadMe and How-To Guide is located here: \n",
    "https://docs.google.com/document/d/1hfkKuHdc5htsAZjkRZWYzMZev2CSRcb4WBH9agrphzE/edit?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7ee412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import these libraries (make sure they are installed before)\n",
    "import bioread\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bd7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional first step - scan the data structure\n",
    "# By seeing the data structure we can modify the script accordingly. \n",
    "# Each ACQ template may have a slightly different structure - different channels used in physio collection means different columns in the DF \n",
    "\n",
    "# use the bioread function on one acq file- this gives us an idea of what it looks like  \n",
    "acq_dataset = bioread.read_file(\"/Volumes/labshare/Nadu/fmcc_winter_spring_quarter/sub49/fmcc_sub49_task_0000.acq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8168fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# check how many columns in this dataset\n",
    "# important for later in the code when creating a dataframe\n",
    "num_cols = len(acq_dataset.channels)\n",
    "print(num_cols)\n",
    " \n",
    "#12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112dcca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GSR - EDA100C  ECG - ECG100C  Feedback Cable - CBLCFMA - Current Feed  \\\n",
      "count   1.226013e+06   1.226013e+06                             1.226013e+06   \n",
      "mean    1.009395e+01  -4.319720e-02                             3.139719e-01   \n",
      "std     9.381568e+00   8.430103e-01                             7.183593e-02   \n",
      "min    -1.556398e+00  -1.000000e+01                            -1.231689e+01   \n",
      "25%     1.524809e-03  -1.492310e-01                             3.021240e-01   \n",
      "50%     1.784058e+01  -2.410889e-02                             3.143311e-01   \n",
      "75%     1.848144e+01  -1.098633e-02                             3.265381e-01   \n",
      "max     2.221069e+01   9.999695e+00                             1.189880e+01   \n",
      "\n",
      "       Stim - Custom, AMI / HLT - A16  Digital (STP Input 0)  \\\n",
      "count                    1.226013e+06           1.226013e+06   \n",
      "mean                    -2.007456e-01           5.632077e-03   \n",
      "std                      1.175066e-01           1.677161e-01   \n",
      "min                     -2.181963e-01           0.000000e+00   \n",
      "25%                     -2.062947e-01           0.000000e+00   \n",
      "50%                     -2.041585e-01           0.000000e+00   \n",
      "75%                     -2.023275e-01           0.000000e+00   \n",
      "max                      4.192421e+00           5.000000e+00   \n",
      "\n",
      "       Digital (STP Input 1)  Digital (STP Input 2)  Digital (STP Input 3)  \\\n",
      "count           1.226013e+06           1.226013e+06           1.226013e+06   \n",
      "mean            2.691652e-03           5.546434e-03           4.893912e-04   \n",
      "std             1.159786e-01           1.664375e-01           4.946432e-02   \n",
      "min             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "25%             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "50%             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "75%             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "max             5.000000e+00           5.000000e+00           5.000000e+00   \n",
      "\n",
      "       Digital (STP Input 4)  Digital (STP Input 5)  Digital (STP Input 6)  \\\n",
      "count           1.226013e+06           1.226013e+06           1.226013e+06   \n",
      "mean            1.028129e-02           3.262608e-04           1.044850e-02   \n",
      "std             2.264968e-01           4.038810e-02           2.283274e-01   \n",
      "min             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "25%             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "50%             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "75%             0.000000e+00           0.000000e+00           0.000000e+00   \n",
      "max             5.000000e+00           5.000000e+00           5.000000e+00   \n",
      "\n",
      "       Digital (STP Input 7)  \n",
      "count           1.226013e+06  \n",
      "mean            2.785452e-03  \n",
      "std             1.179810e-01  \n",
      "min             0.000000e+00  \n",
      "25%             0.000000e+00  \n",
      "50%             0.000000e+00  \n",
      "75%             0.000000e+00  \n",
      "max             5.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# explore the data and scan the structure. \n",
    "# optional step: export a csv of this structure \n",
    "\n",
    "data = {}\n",
    "for channel in acq_dataset.channels:\n",
    "    data[channel.name] = channel.data  # Use channel names as column headers\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display basic statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "#output_path = \"/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/fmcc_w25/fmcc_csv\"\n",
    "#df.to_csv(output_path, index=False, header=True)\n",
    "#print(f\"DataFrame successfully exported to {output_path}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc26678e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSR - EDA100C</th>\n",
       "      <th>ECG - ECG100C</th>\n",
       "      <th>Feedback Cable - CBLCFMA - Current Feed</th>\n",
       "      <th>Stim - Custom, AMI / HLT - A16</th>\n",
       "      <th>Digital (STP Input 0)</th>\n",
       "      <th>Digital (STP Input 1)</th>\n",
       "      <th>Digital (STP Input 2)</th>\n",
       "      <th>Digital (STP Input 3)</th>\n",
       "      <th>Digital (STP Input 4)</th>\n",
       "      <th>Digital (STP Input 5)</th>\n",
       "      <th>Digital (STP Input 6)</th>\n",
       "      <th>Digital (STP Input 7)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.062682</td>\n",
       "      <td>-0.148926</td>\n",
       "      <td>0.299072</td>\n",
       "      <td>-0.202938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.062682</td>\n",
       "      <td>-0.149841</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>-0.210872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.064208</td>\n",
       "      <td>-0.150452</td>\n",
       "      <td>0.311279</td>\n",
       "      <td>-0.202327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.064208</td>\n",
       "      <td>-0.152283</td>\n",
       "      <td>0.268555</td>\n",
       "      <td>-0.201412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.065734</td>\n",
       "      <td>-0.153198</td>\n",
       "      <td>0.314331</td>\n",
       "      <td>-0.202633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.064208</td>\n",
       "      <td>-0.155029</td>\n",
       "      <td>0.289917</td>\n",
       "      <td>-0.203548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.062682</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>0.302124</td>\n",
       "      <td>-0.206905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.064208</td>\n",
       "      <td>-0.158386</td>\n",
       "      <td>0.332642</td>\n",
       "      <td>-0.204464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.062682</td>\n",
       "      <td>-0.161133</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>-0.206600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.065734</td>\n",
       "      <td>-0.164490</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>-0.204159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GSR - EDA100C  ECG - ECG100C  Feedback Cable - CBLCFMA - Current Feed  \\\n",
       "0      22.062682      -0.148926                                 0.299072   \n",
       "1      22.062682      -0.149841                                 0.305176   \n",
       "2      22.064208      -0.150452                                 0.311279   \n",
       "3      22.064208      -0.152283                                 0.268555   \n",
       "4      22.065734      -0.153198                                 0.314331   \n",
       "5      22.064208      -0.155029                                 0.289917   \n",
       "6      22.062682      -0.156250                                 0.302124   \n",
       "7      22.064208      -0.158386                                 0.332642   \n",
       "8      22.062682      -0.161133                                 0.305176   \n",
       "9      22.065734      -0.164490                                 0.341797   \n",
       "\n",
       "   Stim - Custom, AMI / HLT - A16  Digital (STP Input 0)  \\\n",
       "0                       -0.202938                    0.0   \n",
       "1                       -0.210872                    0.0   \n",
       "2                       -0.202327                    0.0   \n",
       "3                       -0.201412                    0.0   \n",
       "4                       -0.202633                    0.0   \n",
       "5                       -0.203548                    0.0   \n",
       "6                       -0.206905                    0.0   \n",
       "7                       -0.204464                    0.0   \n",
       "8                       -0.206600                    0.0   \n",
       "9                       -0.204159                    0.0   \n",
       "\n",
       "   Digital (STP Input 1)  Digital (STP Input 2)  Digital (STP Input 3)  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "5                    0.0                    0.0                    0.0   \n",
       "6                    0.0                    0.0                    0.0   \n",
       "7                    0.0                    0.0                    0.0   \n",
       "8                    0.0                    0.0                    0.0   \n",
       "9                    0.0                    0.0                    0.0   \n",
       "\n",
       "   Digital (STP Input 4)  Digital (STP Input 5)  Digital (STP Input 6)  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "5                    0.0                    0.0                    0.0   \n",
       "6                    0.0                    0.0                    0.0   \n",
       "7                    0.0                    0.0                    0.0   \n",
       "8                    0.0                    0.0                    0.0   \n",
       "9                    0.0                    0.0                    0.0   \n",
       "\n",
       "   Digital (STP Input 7)  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "5                    0.0  \n",
       "6                    0.0  \n",
       "7                    0.0  \n",
       "8                    0.0  \n",
       "9                    0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10 rows \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48d06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths to the folder you want to list\n",
    "\n",
    "# Input path should be folder where all the acq files are located \n",
    "# This is the path to Nasdrive folder \n",
    "biopacpath = \"/Volumes/labshare/Nadu/fmcc_winter_spring_quarter\"\n",
    "\n",
    "\n",
    "# path to output the csv files - make sure there is no final slash. \n",
    "# os.path.join is used later - it expects no final slash \n",
    "# outputdir = '/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/fmcc_w25/fmcc_csv'\n",
    "outputdir = \"/Users/nadezhdabarbashova/Documents/fmcc_heart_rate/raw_csv\"\n",
    "\n",
    "# list of subjects. Have them as character formats \n",
    "# make sure to check conventions like adding a 0 before \n",
    "\n",
    "subjects = [\"49\", \"50\", \"51\", \"52\", \"54\", \"55\", \"56\", \"57\", \"58\", \"61\", \"62\", \"63\", \"65\", \"67\",\n",
    "            \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"76\", \"78\", \"81\", \"82\", \"84\", \"85\", \"87\",\n",
    "           \"88\", \"89\", \"91\", \"93\", \"98\", \"99\", \"100\", \"104\", \n",
    "             \"107\", \"109\", \"110\"]\n",
    "\n",
    "subjects = [\"91\", \"93\", \"98\", \"99\", \"100\", \"104\", \n",
    "             \"107\", \"109\", \"110\"]\n",
    "\n",
    "# remove this if it exists: \n",
    "# subjects.remove(\".DS_Store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaccf62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: 91\n",
      "Processing file: fmcc_sub91_task_0000.acq\n",
      "done creating csv for fmcc_sub91_task_0000.acq\n",
      "Processing file: fmcc_sub91_task_0001.acq\n",
      "done creating csv for fmcc_sub91_task_0001.acq\n",
      "Processing file: fmcc_sub91_task_0002.acq\n",
      "done creating csv for fmcc_sub91_task_0002.acq\n",
      "Processing file: fmcc_sub91_task_0003.acq\n",
      "done creating csv for fmcc_sub91_task_0003.acq\n",
      "Processing file: fmcc_sub91_task_0004.acq\n",
      "done creating csv for fmcc_sub91_task_0004.acq\n",
      "Processing file: fmcc_sub91_task_0005.acq\n",
      "done creating csv for fmcc_sub91_task_0005.acq\n",
      "Processing file: fmcc_sub91_task_0006.acq\n",
      "done creating csv for fmcc_sub91_task_0006.acq\n",
      "Processing file: fmcc_sub91_task_0007.acq\n",
      "done creating csv for fmcc_sub91_task_0007.acq\n",
      "Processing file: fmcc_sub91_task_0008.acq\n",
      "done creating csv for fmcc_sub91_task_0008.acq\n",
      "Processing subject: 93\n",
      "Processing file: fmcc_sub93_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub93_task_0000.acq\n",
      "Processing file: fmcc_sub93_task_0001.acq\n",
      "done creating csv for fmcc_sub93_task_0001.acq\n",
      "Processing file: fmcc_sub93_task_0002.acq\n",
      "done creating csv for fmcc_sub93_task_0002.acq\n",
      "Processing file: fmcc_sub93_task_0003.acq\n",
      "done creating csv for fmcc_sub93_task_0003.acq\n",
      "Processing file: fmcc_sub93_task_0004.acq\n",
      "done creating csv for fmcc_sub93_task_0004.acq\n",
      "Processing file: fmcc_sub93_task_0005.acq\n",
      "done creating csv for fmcc_sub93_task_0005.acq\n",
      "Processing file: fmcc_sub93_task_0006.acq\n",
      "done creating csv for fmcc_sub93_task_0006.acq\n",
      "Processing file: fmcc_sub93_task_0007.acq\n",
      "done creating csv for fmcc_sub93_task_0007.acq\n",
      "Processing file: fmcc_sub93_task_0008.acq\n",
      "done creating csv for fmcc_sub93_task_0008.acq\n",
      "Processing subject: 98\n",
      "Processing file: fmcc_sub98_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub98_task_0000.acq\n",
      "Processing file: fmcc_sub98_task_0001.acq\n",
      "done creating csv for fmcc_sub98_task_0001.acq\n",
      "Processing file: fmcc_sub98_task_0002.acq\n",
      "done creating csv for fmcc_sub98_task_0002.acq\n",
      "Processing file: fmcc_sub98_task_0003.acq\n",
      "done creating csv for fmcc_sub98_task_0003.acq\n",
      "Processing file: fmcc_sub98_task_0004.acq\n",
      "done creating csv for fmcc_sub98_task_0004.acq\n",
      "Processing file: fmcc_sub98_task_0005.acq\n",
      "done creating csv for fmcc_sub98_task_0005.acq\n",
      "Processing file: fmcc_sub98_task_0006.acq\n",
      "done creating csv for fmcc_sub98_task_0006.acq\n",
      "Processing file: fmcc_sub98_task_0007.acq\n",
      "done creating csv for fmcc_sub98_task_0007.acq\n",
      "Processing file: fmcc_sub98_task_0008.acq\n",
      "done creating csv for fmcc_sub98_task_0008.acq\n",
      "Processing subject: 99\n",
      "Processing file: fmcc_sub99_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub99_task_0000.acq\n",
      "Processing file: fmcc_sub99_task_0001.acq\n",
      "done creating csv for fmcc_sub99_task_0001.acq\n",
      "Processing file: fmcc_sub99_task_0002.acq\n",
      "done creating csv for fmcc_sub99_task_0002.acq\n",
      "Processing file: fmcc_sub99_task_0003.acq\n",
      "done creating csv for fmcc_sub99_task_0003.acq\n",
      "Processing file: fmcc_sub99_task_0004.acq\n",
      "done creating csv for fmcc_sub99_task_0004.acq\n",
      "Processing file: fmcc_sub99_task_0005.acq\n",
      "done creating csv for fmcc_sub99_task_0005.acq\n",
      "Processing file: fmcc_sub99_task_0006.acq\n",
      "done creating csv for fmcc_sub99_task_0006.acq\n",
      "Processing file: fmcc_sub99_task_0007.acq\n",
      "done creating csv for fmcc_sub99_task_0007.acq\n",
      "Processing file: fmcc_sub99_task_0008.acq\n",
      "done creating csv for fmcc_sub99_task_0008.acq\n",
      "Processing subject: 100\n",
      "Processing file: fmcc_sub100_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub100_task_0000.acq\n",
      "Processing file: fmcc_sub100_task_0001.acq\n",
      "done creating csv for fmcc_sub100_task_0001.acq\n",
      "Processing file: fmcc_sub100_task_0002.acq\n",
      "done creating csv for fmcc_sub100_task_0002.acq\n",
      "Processing file: fmcc_sub100_task_0003.acq\n",
      "done creating csv for fmcc_sub100_task_0003.acq\n",
      "Processing file: fmcc_sub100_task_0004.acq\n",
      "done creating csv for fmcc_sub100_task_0004.acq\n",
      "Processing file: fmcc_sub100_task_0005.acq\n",
      "done creating csv for fmcc_sub100_task_0005.acq\n",
      "Processing file: fmcc_sub100_task_0006.acq\n",
      "done creating csv for fmcc_sub100_task_0006.acq\n",
      "Processing file: fmcc_sub100_task_0007.acq\n",
      "done creating csv for fmcc_sub100_task_0007.acq\n",
      "Processing file: fmcc_sub100_task_0008.acq\n",
      "done creating csv for fmcc_sub100_task_0008.acq\n",
      "Processing subject: 104\n",
      "Processing file: fmcc_sub104_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub104_task_0000.acq\n",
      "Processing file: fmcc_sub104_task_0001.acq\n",
      "done creating csv for fmcc_sub104_task_0001.acq\n",
      "Processing file: fmcc_sub104_task_0002.acq\n",
      "done creating csv for fmcc_sub104_task_0002.acq\n",
      "Processing file: fmcc_sub104_task_0003.acq\n",
      "done creating csv for fmcc_sub104_task_0003.acq\n",
      "Processing file: fmcc_sub104_task_0004.acq\n",
      "done creating csv for fmcc_sub104_task_0004.acq\n",
      "Processing file: fmcc_sub104_task_0005.acq\n",
      "done creating csv for fmcc_sub104_task_0005.acq\n",
      "Processing file: fmcc_sub104_task_0006.acq\n",
      "done creating csv for fmcc_sub104_task_0006.acq\n",
      "Processing file: fmcc_sub104_task_0007.acq\n",
      "done creating csv for fmcc_sub104_task_0007.acq\n",
      "Processing file: fmcc_sub104_task_0008.acq\n",
      "done creating csv for fmcc_sub104_task_0008.acq\n",
      "Processing subject: 107\n",
      "Processing file: fmcc_sub107_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub107_task_0000.acq\n",
      "Processing file: fmcc_sub107_task_0001.acq\n",
      "done creating csv for fmcc_sub107_task_0001.acq\n",
      "Processing file: fmcc_sub107_task_0002.acq\n",
      "done creating csv for fmcc_sub107_task_0002.acq\n",
      "Processing file: fmcc_sub107_task_0003.acq\n",
      "done creating csv for fmcc_sub107_task_0003.acq\n",
      "Processing file: fmcc_sub107_task_0004.acq\n",
      "done creating csv for fmcc_sub107_task_0004.acq\n",
      "Processing file: fmcc_sub107_task_0005.acq\n",
      "done creating csv for fmcc_sub107_task_0005.acq\n",
      "Processing file: fmcc_sub107_task_0006.acq\n",
      "done creating csv for fmcc_sub107_task_0006.acq\n",
      "Processing file: fmcc_sub107_task_0007.acq\n",
      "done creating csv for fmcc_sub107_task_0007.acq\n",
      "Processing file: fmcc_sub107_task_0008.acq\n",
      "done creating csv for fmcc_sub107_task_0008.acq\n",
      "Processing subject: 109\n",
      "Processing file: fmcc_sub109_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub109_task_0000.acq\n",
      "Processing file: fmcc_sub109_task_0001.acq\n",
      "done creating csv for fmcc_sub109_task_0001.acq\n",
      "Processing file: fmcc_sub109_task_0002.acq\n",
      "done creating csv for fmcc_sub109_task_0002.acq\n",
      "Processing file: fmcc_sub109_task_0003.acq\n",
      "done creating csv for fmcc_sub109_task_0003.acq\n",
      "Processing file: fmcc_sub109_task_0004.acq\n",
      "done creating csv for fmcc_sub109_task_0004.acq\n",
      "Processing file: fmcc_sub109_task_0005.acq\n",
      "done creating csv for fmcc_sub109_task_0005.acq\n",
      "Processing file: fmcc_sub109_task_0006.acq\n",
      "done creating csv for fmcc_sub109_task_0006.acq\n",
      "Processing file: fmcc_sub109_task_0007.acq\n",
      "done creating csv for fmcc_sub109_task_0007.acq\n",
      "Processing file: fmcc_sub109_task_0008.acq\n",
      "done creating csv for fmcc_sub109_task_0008.acq\n",
      "Processing subject: 110\n",
      "Processing file: fmcc_sub110_task_0000.acq\n",
      "folder not found - will be created\n",
      "done creating csv for fmcc_sub110_task_0000.acq\n",
      "Processing file: fmcc_sub110_task_0001.acq\n",
      "done creating csv for fmcc_sub110_task_0001.acq\n",
      "Processing file: fmcc_sub110_task_0002.acq\n",
      "done creating csv for fmcc_sub110_task_0002.acq\n",
      "Processing file: fmcc_sub110_task_0003.acq\n",
      "done creating csv for fmcc_sub110_task_0003.acq\n",
      "Processing file: fmcc_sub110_task_0004.acq\n",
      "done creating csv for fmcc_sub110_task_0004.acq\n",
      "Processing file: fmcc_sub110_task_0005.acq\n",
      "done creating csv for fmcc_sub110_task_0005.acq\n",
      "Processing file: fmcc_sub110_task_0006.acq\n",
      "done creating csv for fmcc_sub110_task_0006.acq\n",
      "Processing file: fmcc_sub110_task_0007.acq\n",
      "done creating csv for fmcc_sub110_task_0007.acq\n",
      "Processing file: fmcc_sub110_task_0008.acq\n",
      "done creating csv for fmcc_sub110_task_0008.acq\n",
      "done processing all subjects\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sub in subjects:\n",
    "#Below convert the acq files to matlab files\n",
    "    inputdir = biopacpath + \"/sub\" + sub\n",
    "    allfiles = os.listdir(inputdir)\n",
    "    #print(f\"Files in directory {inputdir}: {allfiles}\")  # Debugging: list files\n",
    "\n",
    "    #Get the acq file names that only task related\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(inputdir):\n",
    "        print(f\"Directory does not exist: {inputdir}\")\n",
    "        continue  # Skip this subject if directory doesn't exist\n",
    "\n",
    "    print(f\"Processing subject: {sub}\")  # Debugging: confirm subject being processed\n",
    "    #print(f\"directory: {inputdir}\")\n",
    "\n",
    "    # Find prefix for fmcc \n",
    "    # Then get task-related .acq files - must end with acq, must have task (no physio)\n",
    "     \n",
    "    taskfnli = [item for item in allfiles if item.endswith('.acq') and 'task' in item]\n",
    "    \n",
    "    #print(f\"Task-related files: {taskfnli}\")  # Debugging: check filtered files\n",
    "    \n",
    "    for inputfn in taskfnli:\n",
    "        print(f\"Processing file: {inputfn}\")\n",
    "        \n",
    "        # filename = main directory + filename of this acq file \n",
    "        fn = os.path.join(inputdir, inputfn)\n",
    "    \n",
    "        # there are only 12 channels. use bioread to extract info from each channel \n",
    "        # rename them to go from 1 to 12 instead of 0 to 11 \n",
    "        acq_dataset = bioread.read_file(fn)\n",
    "        chan1 = acq_dataset.channels[0].data \n",
    "        chan2 = acq_dataset.channels[1].data\n",
    "        chan3 = acq_dataset.channels[2].data\n",
    "        chan4 = acq_dataset.channels[3].data\n",
    "        chan5 = acq_dataset.channels[4].data\n",
    "        chan6 = acq_dataset.channels[5].data\n",
    "        chan7 = acq_dataset.channels[6].data\n",
    "        chan8 = acq_dataset.channels[7].data\n",
    "        chan9 = acq_dataset.channels[8].data\n",
    "        chan10 = acq_dataset.channels[9].data\n",
    "        chan11 = acq_dataset.channels[10].data\n",
    "        chan12 = acq_dataset.channels[11].data\n",
    "\n",
    "        # make a dataframe by combining these channels \n",
    "        df = pd.DataFrame({\"1\": chan1, \"2\": chan2, \"3\": chan3, \"4\": chan4, \"5\": chan5, \n",
    "                   \"6\": chan6, \"7\": chan7, \"8\": chan8, \"9\": chan9, \"10\": chan10, \n",
    "                   \"11\": chan11, \"12\": chan12})\n",
    "\n",
    "        # if you want to see the structure at this stage - print first 10 rows: \n",
    "        # df.head(10)\n",
    "        \n",
    "        #create output sub-directory for this subject - main directory + sub## \n",
    "        outputsubdir = outputdir + \"/sub\" + sub\n",
    "        \n",
    "        #if the folder is not found - create a folder \n",
    "        if not os.path.exists(outputsubdir):\n",
    "            \n",
    "            # If it doesn't exist, create the folder\n",
    "            print(\"folder not found - will be created\")\n",
    "            os.makedirs(outputsubdir)   \n",
    "            #mat_fn = inputfn.replace(\".acq\", \".mat\")\n",
    "        \n",
    "        # copy the acq filename but now end it with .csv \n",
    "        csv_fn = inputfn.replace(\".acq\", \".csv\")\n",
    "              \n",
    "        # construct and output file path from filename and output directory    \n",
    "        csv_file = os.path.join(outputsubdir, csv_fn)\n",
    " \n",
    "        # Save the NumPy array to a MATLAB file\n",
    "        #savemat(mat_file, {'data': df.to_numpy()})\n",
    "            \n",
    "        # turn the df into a csv file and save it to the csv file directory \n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"done creating csv for {inputfn}\")\n",
    "        \n",
    "        \n",
    "print(\"done processing all subjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79ff3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below just to get the sample rate  \n",
    "# EDASampleRate.append(acq_dataset.channels[0].samples_per_second)\n",
    "# TrigerSampleRate.append(acq_dataset.channels[2].samples_per_second)\n",
    "# make dataframe and save\n",
    "# sampleRdf = pd.DataFrame({\"participant\": subli, \"run\": runli, \"EDASampleRate\": EDASampleRate, \"TrigerSampleRate\":TrigerSampleRate})\n",
    "# sampleRdf.to_csv(\"/Users/jingyiwang/Dropbox/LEAP_Neuro_Lab/researchProjects/jingyi_documents/emotion_motor_grant/AA_fMRIAnalyses/EDAAnalysis/SampleRate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae6f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nadezhdabarbashova/Library/CloudStorage/Dropbox/LEAP_Neuro_Lab/researchProjects/nadu/fmcc/data/fmcc_w25/acq_data\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
