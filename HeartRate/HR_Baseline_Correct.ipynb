{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f21f36",
   "metadata": {},
   "source": [
    "## Heart Rate Processing and Baseline Correction \n",
    "Script by Nadu Barbashova \n",
    "\n",
    "This Script is also on Github in my Psychophysiology Folder: \n",
    "https://github.com/n-barbashova/psychophysiology/tree/master/HeartRate \n",
    "\n",
    "Neurokit Documentation: \n",
    "\n",
    "\n",
    "### About this script: \n",
    "My Experiment: \n",
    "Participants wait 60 seconds for stimuli (shocks or stimulations). In this time they watch a 60 second coundown. For 30 of these seconds they complete the flanker task and for the other 30 seconds they just watch the countdown. The order depends on which countdown it is. There are 36 countdowns, divided into 9 runs. \n",
    "\n",
    "The goal is to see how the heartrate is affected by the condition (is this a threat countdown (leading to shock) or a no-threat countdown (leading to stim)). I want to also see how heart rate is affected when it's the flanker task epoch vs the countdown epoch. \n",
    "\n",
    "\n",
    "### What this script does:\n",
    "This script takes the pre-processed ECG data and further processes it using functions from Neurokit. It cleans the heart rate, finds event codes and using the event codes, labels which condition this is (shock or stim), which interval it is (flanker or countdown). In addition to processing the heart rate it also does one second heart rate baseline correction, comparing the heart rate in the given interval to the heart rate in the one second before the countdown began. \n",
    "\n",
    "\n",
    "### Input required: \n",
    "\n",
    "\n",
    "### Output from this script: \n",
    "This script will output a new file for each input file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1097dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load NeuroKit and other useful packages (make sure they are installed)\n",
    "import neurokit2 as nk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# subject ID's to loop through \n",
    "IDs = [\"49\", \"50\", \"51\", \"52\", \"54\", \"55\", \"56\", \"57\", \"58\", \"61\", \"62\", \"63\", \"65\", \"67\",\n",
    "          \"68\", \"69\", \"70\", \"72\", \"73\", \"74\", \"76\", \"78\", \"81\", \"82\", \"84\",\n",
    "       \"85\", \"86\", \"87\", \"88\", \"89\", \"91\", \"93\", \"98\", \"99\", \"100\"]\n",
    "\n",
    "# runs to loop through \n",
    "runs = [ 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "#input_dir = \n",
    "outdir = \"/Users/nadezhdabarbashova/Desktop/fmcc_timing/neurokit/\"\n",
    "\n",
    "# plot the heart rate - it creates pretty funny plots where you can see literally evety heart beat.  \n",
    "# Not the most useful but nice to double check the data for noise or disrupted signal \n",
    "figs_dir = \"/Users/nadezhdabarbashova/Desktop/fmcc_timing/HR/figs/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Heart Rate Processing and Baseline Correction \n",
    "### updated to have the events labelled\n",
    "\n",
    "# Define Directories\n",
    "flanker_start_events = [3, 7, 11, 15]  # Define relevant event codes\n",
    "\n",
    "\n",
    "for ID in IDs:\n",
    "    for run in runs:\n",
    "        try:\n",
    "            print(f\"Processing {ID} Run {run}...\")\n",
    "\n",
    "            # Load data\n",
    "            fn = f\"/Users/nadezhdabarbashova/Desktop/fmcc_timing/HR/{ID}_run{run}.txt\"\n",
    "            data = pd.read_csv(fn, sep=\"\\t\", header=None)\n",
    "            data.columns = [\"timepoint\", \"ECG\", \"EVENT\"]\n",
    "\n",
    "            # Process ECG data (clean, detect peaks, compute HR)\n",
    "            signals, info = nk.ecg_process(data[\"ECG\"], sampling_rate=100)\n",
    "\n",
    "            # Merge processed ECG data with original event data\n",
    "            datasignal = pd.concat([signals, data[[\"timepoint\", \"EVENT\"]]], axis=1)\n",
    "\n",
    "            # --------------------------------------\n",
    "            # Add Condition Labels to `datasignal`\n",
    "            # --------------------------------------\n",
    "            \n",
    "            datasignal['event_chunk_countdown'] = 0\n",
    "            datasignal['event_chunk_flanker'] = 0\n",
    "            datasignal['threat_type'] = \"\"\n",
    "            datasignal['distance_type'] = \"\"\n",
    "            datasignal['event_type'] = \"\"\n",
    "\n",
    "            event_pairs_countdown = [(1, 2), (5, 6), (9, 10), (13, 14)]\n",
    "            event_pairs_flanker = [(3, 4), (7, 8), (11, 12), (15, 16)]\n",
    "\n",
    "            for start, end in event_pairs_countdown:\n",
    "                if (datasignal['EVENT'] == start).any() and (datasignal['EVENT'] == end).any():\n",
    "                    start_idx = datasignal.index[datasignal['EVENT'] == start][0]\n",
    "                    end_idx = datasignal.index[datasignal['EVENT'] == end][0]\n",
    "                    datasignal.loc[start_idx:end_idx + 1, 'event_chunk_countdown'] = start\n",
    "\n",
    "            for start, end in event_pairs_flanker:\n",
    "                if (datasignal['EVENT'] == start).any() and (datasignal['EVENT'] == end).any():\n",
    "                    start_idx = datasignal.index[datasignal['EVENT'] == start][0]\n",
    "                    end_idx = datasignal.index[datasignal['EVENT'] == end][0]\n",
    "                    datasignal.loc[start_idx:end_idx, 'event_chunk_flanker'] = start\n",
    "\n",
    "            # Label conditions\n",
    "            datasignal.loc[datasignal['event_chunk_countdown'] == 1, ['threat_type', 'distance_type', 'event_type']] = ['shock', 'distal', 'distal shock countdown']\n",
    "            datasignal.loc[datasignal['event_chunk_flanker'] == 3, ['threat_type', 'distance_type', 'event_type']] = ['shock', 'distal', 'distal shock flanker']\n",
    "            datasignal.loc[datasignal['event_chunk_countdown'] == 5, ['threat_type', 'distance_type', 'event_type']] = ['shock', 'proximal', 'proximal shock countdown']\n",
    "            datasignal.loc[datasignal['event_chunk_flanker'] == 7, ['threat_type', 'distance_type', 'event_type']] = ['shock', 'proximal', 'proximal shock flanker']\n",
    "            datasignal.loc[datasignal['event_chunk_countdown'] == 9, ['threat_type', 'distance_type', 'event_type']] = ['stim', 'distal', 'distal stim countdown']\n",
    "            datasignal.loc[datasignal['event_chunk_flanker'] == 11, ['threat_type', 'distance_type', 'event_type']] = ['stim', 'distal', 'distal stim flanker']\n",
    "            datasignal.loc[datasignal['event_chunk_countdown'] == 13, ['threat_type', 'distance_type', 'event_type']] = ['stim', 'proximal', 'proximal stim countdown']\n",
    "            datasignal.loc[datasignal['event_chunk_flanker'] == 15, ['threat_type', 'distance_type', 'event_type']] = ['stim', 'proximal', 'proximal stim flanker']\n",
    "\n",
    "            # Add 'end' condition labels\n",
    "            datasignal.loc[datasignal['EVENT'] == 2, 'event_type'] = 'distal shock countdown end'\n",
    "            datasignal.loc[datasignal['EVENT'] == 6, 'event_type'] = 'proximal shock countdown end'\n",
    "            datasignal.loc[datasignal['EVENT'] == 10, 'event_type'] = 'distal stim countdown end'\n",
    "            datasignal.loc[datasignal['EVENT'] == 14, 'event_type'] = 'proximal stim countdown end'\n",
    "\n",
    "            # Remove rows where event_chunk_flanker == 0\n",
    "\n",
    "        \n",
    "            # Save full dataset with ECG metrics\n",
    "            save_filename = os.path.join(outdir, f\"{ID}_EKG_ECode_HeartRate{run}.csv\")\n",
    "            \n",
    " \n",
    "            datasignal.to_csv(save_filename, index=False)\n",
    "            print(f\"‚úÖ Saved full ECG dataset: {save_filename}\")\n",
    "\n",
    "            # Identify Flanker Start Events\n",
    "            flanker_events_df = datasignal[datasignal[\"EVENT\"].isin(flanker_start_events)]\n",
    "            event_indices = flanker_events_df.index.tolist()\n",
    "\n",
    "            if not event_indices:\n",
    "                print(f\"‚ö†Ô∏è No flanker start events found for {ID} run {run}. Skipping epoch creation.\")\n",
    "                continue\n",
    "\n",
    "            # Create Epochs (using processed ECG data) - this is a dictionary \n",
    "            epochs = nk.epochs_create(\n",
    "                data = datasignal,  # Use full processed dataset\n",
    "                events = event_indices,\n",
    "                sampling_rate=100, \n",
    "                epochs_start=-1, # start at -1 second before the even \n",
    "                epochs_end=30\n",
    "            )\n",
    "\n",
    "            if not epochs:\n",
    "                #print(f\"No epochs created for {ID} run {run}.\")\n",
    "                continue\n",
    "\n",
    "            # Save Each Epoch Separately\n",
    "            for event_label, epoch_df in epochs.items():\n",
    "                \n",
    "                ### NEW CODE: Baseline Correction\n",
    "                try:\n",
    "                    # Compute baseline (ECG_Rate) from -1 second to event onset (first 100 rows)\n",
    "                    ecg_baseline = epoch_df[\"ECG_Rate\"].iloc[:100].mean()  \n",
    "\n",
    "                    # Compute the mean ECG_Rate for the 30 seconds after event onset (next 3000 rows)\n",
    "                    ecg_mean = epoch_df[\"ECG_Rate\"].iloc[100:].mean()  \n",
    "\n",
    "                    # Create a new column in epoch_df for the corrected ECG rate\n",
    "                    epoch_df[\"ECG_Baseline_Corrected\"] = epoch_df[\"ECG_Rate\"] - ecg_baseline  \n",
    "                    print(\"Baseline Correction Done\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error in baseline correction for {ID} run {run}, event {event_label}: {e}\")\n",
    "                    epoch_df[\"ECG_Rate_Corrected\"] = epoch_df[\"ECG_Rate\"]  # If error, keep original values\n",
    "\n",
    "                epoch_df = epoch_df[epoch_df[\"event_chunk_flanker\"] != 0]\n",
    "                epoch_df = epoch_df.rename(columns={\"Label\": \"countdownNum\"})                \n",
    "                countdown_num = epoch_df[\"countdownNum\"].iloc[0] if \"countdownNum\" in epoch_df.columns else event_label\n",
    "                epoch_filename = os.path.join(outdir, f\"{ID}_EKG_epoch_Flanker_run{run}_{countdown_num}.csv\")\n",
    "                epoch_df.to_csv(epoch_filename, index=False)\n",
    "                print(f\"üíæ Saved epoch: {epoch_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {ID} run {run}: {e}\")\n",
    "\n",
    "print(\"‚úÖ Processing complete for all subjects and runs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7852e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, the epochs_create function will take those events and find a one second baseline \n",
    "# (-2000 samples when using a 2000hz sampling rate) and also an epoch duration of 4 seconds (8000 samples).\n",
    "# data has been already downsampled by 20 which means it should be 100 samples now \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bede6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at one example of the output \n",
    "# understand these cols: \n",
    "# examine these columns \n",
    "# ECG_Raw, ECG_Clean, ECG_Rate, ECG_Quality timepoint\tEVENT\tIndex\tcountdownNum\tECG_Baseline_Corrected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf79a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep this as a reference \n",
    "# example code\n",
    "eventIndex = events[\"onset\"]\n",
    "eventList = [] \n",
    "\n",
    "for i in eventIndex: \n",
    "    d = df1[\"Event\"][i]\n",
    "    eventList.append(d)\n",
    "\n",
    "for epoch_index in epoch4: \n",
    "    df[epoch_index] = {} \n",
    "    epoch = epochs4[epoch_index]\n",
    "    ecg_baseline = epoch[\"hr\"].loc[-2000:0].mean() \n",
    "    ecg_mean = epoch[\"hr\"].loc[0:8000].mean()\n",
    "    # store ECG in df \n",
    "    df[epoch_index][\"hr\"] = ecg_mean - ecg_baseline \n",
    "\n",
    "df = pd.DataFrame.from_dict(df, orient = \"index\")\n",
    "df[\"Event\"] = eventList \n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original sampling rate was 2000 - but has been downsampled by 20\n",
    "# sampling rate is 100\n",
    "# 30 seconds = 100 * 30 = 3000 rows \n",
    "\n",
    "# create a basline 1 second before\n",
    "# then create a mean of the next 30 seconds\n",
    "# not sure what hr is \n",
    "\n",
    "for epoch_index in epoch4: \n",
    "    df[epoch_index] = {} \n",
    "    epoch = epochs4[epoch_index]\n",
    "    ecg_baseline = epoch[\"hr\"].loc[-100:0].mean()  # change to 100  \n",
    "    ecg_mean = epoch[\"hr\"].loc[0:3000].mean() # this should be 30 seconds \n",
    "    df[epoch_index][\"hr\"] = ecg_mean - ecg_baseline \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d3d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87558cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037156e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
